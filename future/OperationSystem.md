
[TOC]


------



# 计算机系统概述

![image-20220526165354046](../images/image-20220526165354046.png)

## 操作系统的基本概念

### 操作系统的概念和特征

**操作系统** 是指 **控制和管理**整个计算机系统的硬件与软件资源，合理地**组织、调度**计算机的工作与资源的分配，进而为用户和其他软件**提供方便接口与环境**的**程序集合**。**操作系统是计算机系统中最基本的系统软件**
	
+ 计算机系统**自下而上**分为4部分：**硬件、操作系统、应用程序、用户** （划分与计算机组成原理不同）
	
+ 操作系统的特征 （**并发、共享、虚拟、异步**）
	
	+ 并发（**Concurrence**）
		+ 操作系统的并发性是通过 **分时** 得以实现的
	      + 并发：**同一时间间隔**
	        
		      > 9:00到9:30 吃饭，9:30到10:00 学习，则在 9:00到10:00这段间隔里面，吃饭与学习并发
	        
		    + 并行：**同一时刻**，并行性需要有相关硬件的支持，如**多流水线**、或 **多处理机硬件环境**
		
	+ 共享（**Sharing**）（**互斥共享方式** 与 **同时访问方式**）
		+ 指系统中的资源，可供内存中多个 **并发执行 **的进程共同使用
	      + 互斥共享方式
	        仅当进程访问完并释放该资源后，才允许另一个进程对该资源进行访问。
	        一段时间内，只允许一个进程访问的资源，称为 **临界资源** 或 **独占资源**。计算机系统中的**大多数物理设备** 及某些软件中所用的 **栈、变量和表格**，都属于 **临界资源**。
	      + 同时访问方式
	        允许在一段时间内由多个进程**“同时”访问**，“同时”是宏观概念，微观上，这些进程是 **交替地对该资源进行访问，即“分时共享”**。典型资源是 **磁盘设备**。
	
	        > 互斥共享 要求一种资源在一段时间内（哪怕是一段很小的时间）只能满足一个请求，否则就会出现严重问题。而 同时访问共享 通常要求一个请求分几个时间片段间隔地完成，其效果与连续完成的效果相同。
	
	   + **并发** 和 **共享** 是操作系统两个最基本的特征，两者之间互为存在的条件
	
	        + **资源共享**是以程序的并发为条件的，若系统不允许程序**并发执行**，则自然 **不存在资源共享问题**
	        + 若系统不能对**资源共享**实施有效的管理，则必将影响到程序的**并发执行**，甚至根本无法**并发执行**
	
	+ 虚拟（**Virtual**）
	   把一个物理上的实体，变为若干逻辑上的对应物。实现虚拟的技术，称为 **虚拟技术**，虚拟技术可归纳为 **时分复用技术** （处理器的分时共享） 和 **空分复用技术** （虚拟存储器）
	
	   + 虚拟处理器技术
	
	   	通过多道程序设计技术，让多道程序并发执行，来分时使用一个处理器
	
	   + 虚拟存储器技术
	
	   	将一台机器的物理存储器变为虚拟存储器，以便从逻辑上扩充存储器的容量
	
	   + 虚拟设备技术
	
		将一台物理I/O设备虚拟为多台逻辑上的I/O设备
	
	+ 异步（**Asynchronism**）
	   多道程序环境允许多个程序并发执行，但由于资源有限，进程的执行并不是一贯到底的，而是走走停停，它以不可预知的速度向前推进
	   
### 操作系统的目标和功能（**处理器管理、存储器管理、设备管理、文件管理、向用户提供接口、扩充机器**）

+ 操作系统作为计算机系统资源的管理者
	
	+ 处理器管理
		+ 多道程序环境下，处理机的分配和运行都以进程（**或线程**）为基本单位，因而对处理机的管理可归结为对进程的管理。
		+ 并发是指在计算机内**同时运行多个进程**，因而进程的**创建、撤销、管理、避免冲突、合理共享**就是 **进程管理** 的最主要任务。**进程管理**的主要功能包括 **进程控制、进程同步、进程通信、死锁处理、处理机调度** 等
	
	+ 存储器管理
		包括 **内存分配与回收、地址映射、内存保护与共享、内存扩充** 等功能
	+ 文件管理
		包括 **文件存储空间的管理、目录管理、文件读写管理和保护**
	+ 设备管理
		主要任务是 **完成用户的I/O请求，方便用户使用各种设备，提高设备的利用率**， 包括 **缓冲管理、设备分配、设备处理、虚拟设备** 等功能
	+ 操作系统作为用户与计算机硬件系统之间的接口（**命令接口、程序接口**）
		+ 命令接口
			+ 联机命令接口（**交互式命令接口**）
				适用于 **分时或实时系统** 的接口
	        + 脱机命令接口（**批处理命令接口**）
				适用于 **批处理系统**，脱机用户不能直接干预作业的运行。
		+ 程序接口
	        	由一组**系统调用（也称广义指令）**组成

## 操作系统的发展与分类

## 操作系统的运行环境

### 操作系统的运行机制

+ CPU通常执行两种不同性质的程序

  + `操作系统内核程序`
  + `用户自编程序`（即**系统外层的应用程序**，或简称**应用程序**）

+ **操作系统内核程序**是**用户自编程序**的管理者，因此内核程序要执行一些**特权指令**，而**用户自编程序**出于安全考虑不能执行这些指令。

+ `特权指令`：**计算机中不允许用户直接使用的指令**，如**I/O**指令、**置中断**指令，存取用于内存保护的寄存器、送**程序状态字**到**程序状态字寄存器**等的指令。具体实现上，将CPU的状态划分为**用户态**（目态）和**核心态**（**管态、内核态**）。**用户自编程序**运行在**用户态**，**操作系统内核程序**运行在**核心态**。

+ 一些与硬件关联较紧密的模块，如**时钟管理**、**中断处理**、**设备驱动**等处于最低层。其次是运行频率较高的程序，如**进程管理**、**存储器管理**和**设备管理**等。这两部分内容构成了操作系统的内核。这部分内容的指令操作工作在**核心态**。

+ **内核**是计算机上配置的底层软件，是计算机功能的延伸，内核包含以下4方面内容

  + `时钟管理`

    + 在计算机的各种部件中，**时钟**是最关键的设备。
    + 时钟的第一功能是**计时**，操作系统需要通过时钟管理，向用户提供标准的系统时间。
    + 通过**时钟中断**的管理，可以实现进程的切换。
      + 在**分时操作系统**中采用时间片轮转调度
      + 在**实时系统**中按截止时间控制运行
      + 在**批处理系统**中通过时钟管理来衡量一个作业的运行程度

  + `中断机制`

    + 引入中断技术的初衷是**提高多道程序运行环境中CPU的利用率**，而且主要是针对外部设备。例如，键盘或鼠标信息的输入、进程的管理和调度、系统功能的调用、设备驱动、文件访问等。现在操作系统是靠**中断**驱动的软件。
    + 中断机制中，只有一小部分功能属于内核，它们负责**保护**和**恢复中断现场的信息**，**转移控制权**到相关的处理程序。这样可以**减少中断的处理时间**，提高系统的并行处理能力。

  + `原语`

    + 把具有以下特点的程序称为**原语**
      + 处于操作系统的**最低层**，是最接近硬件的部分
      + 这些程序的运行具有**原子性**，其操作只能一气呵成（主要从系统安全性和便于管理考虑）
      + 这些程序的**运行时间都较短**，而且调用频繁
    + 定义原语的直接方法是**关闭中断**，让其所有动作不可分割地完成后再打开中断。
    + 系统中的**设备驱动、CPU切换、进程通信**等功能中的部分操作都可定义为**原语**，使它们成为内核的组成部分。

  + `系统控制的数据结构及处理`

    + 系统中用来登记状态信息的数据结构很多，如**作业控制块、进程控制块（PCB）、设备控制块、各类链表、消息队列、缓冲区、空闲区登记表、内存分配表**

    + 为了实现**有效的管理**，系统需要一些基本的操作，常见的如下3种

      + `进程管理`

        **进程状态管理**、**进程调度和分派**、**创建与撤销进程控制块**等。

      + `存储器管理`

        **存储器的空间分配和回收**、**内存信息保护程序**、**代码对换程序**等。

      + `设备管理`

        **缓冲区管理**、**设备分配和回收**等

+ **中断**和**异常**的概念

  + 系统不允许用户程序实现核心态的功能，而它们又必须使用这些功能。因此，需要在核心态建立一些“门”，以便实现**从用户态进入核心态**。在实际操作系统中，CPU运行上层程序时唯一能进入这些“门”的途径就是通过**中断**或**异常**。

  + 发生**中断**或**异常**时，运行**用户态**的CPU会立即进入**核心态**，这是通过**硬件**实现的。

  + 操作系统的发展过程大体上就是一个想方设法不断**提高资源利用率**的过程，而提高资源利用率就需要在程序并**未使用**某种资源时，把它对那种资源的占有权**释放**，而这一行为就需要通过**中断**实现。

  + **中断（Interruption）**也称外中断，指**来自CPU执行指令以外的事件的发生**

    + 如设备发出的I/O结束中断，表示设备输入/输出处理已经完成，希望处理机能够向设备发下一个输入/输出请求，同时让完成输入/输出后的程序继续运行。
    + **时钟中断**，表示一个固定的时间片已到，让处理机处理计时、启动定时运行的任务等。这一类中断通常是与**当前指令执行无关**的事件，即它们与当前处理机运行的程序无关。

  + **异常（Exception）**也称**内中断、例外、或陷入（trap）**，指**源自CPU执行指令内部的事件**，如程序的非法操作码、地址越界、算术溢出、虚存系统的缺页及专门的陷入指令等引起的事件。对异常的处理一般要**依赖于当前程序的运行现场**，而且异常不能被屏蔽，一旦出现应立即处理。

    ![image-20220602171428645](../images/image-20220602171428645.png)

  + 中断处理的**过程**

    ![image-20220602171757667](../images/image-20220602171757667.png)

    + `关中断`

      CPU响应中断后，首先要保护程序的现场状态，在保护现场的过程中，**CPU不应响应更高级中断源的中断请求**。否则，若现场保存不完整，在中断服务程序结束后，也就不能正确恢复并继续执行现行程序。

    + `保存断点`

      为保证中断服务执行完毕后能正确地返回到原来的程序，必须将原来的程序的**断点（即程序计数器PC）**保存起来。

    + `中断服务程序寻址`

      实质是**取出中断服务程序的入口地址**送入程序计数器PC。

    + `保存现场和屏蔽字`

      进入中断服务程序后，首先要保存现场，现场信息一般是指**程序状态字寄存器PSWR（Program Status Word Register）**和某些通用寄存器的内容。

    + `开中断`

      允许更高级中断请求得到响应

    + `执行中断服务程序`

      这是中断请求的目的。

    + `关中断`

      保证在恢复现场和屏蔽字时不被中断

    + `恢复现场和屏蔽字`

      将现场和屏蔽字恢复到原来的状态

    + `开中断、中断返回`

      中断服务程序的最后一条指令通常是一条中断返回指令，使其返回到原程序的断点处，以便继续执行原程序。

+ 系统调用

  + 指用户在程序中调用操作系统所提供的一些子功能，系统调用可视为特殊的**公共子程序**。系统中的各种共享资源都由操作系统统一掌管，因此在此用户程序中，凡是与**资源**有关的操作（**存储分配、进行I/O传输及管理文件等**），都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。通常，一个操作系统提供的系统调用命令由几十条乃至上百条之多。这些系统调用按功能可分为如下几类
    + `设备管理`
      + 完成设备的**请求或释放**，以及**设备启动**等功能

    + `文件管理`
      + 完成文件的**读、写、创建、删除**等功能

    + `进程控制`
      + 完成进程的**创建、撤销、阻塞、唤醒**等功能

    + `进程通信`
      + 完成进程之间的**消息传递**或**信号传递**等功能

    + `内存管理`
      + 完成内存的**分配、回收、获取作用占用内存区大小、始址**等功能

  + 系统调用相关功能设计**系统资源管理、进程管理**之类的操作，必须需要使用某些**特权指令**才能完成，所以系统调用的处理需要由**操作系统内核程序**负责完成，要运行在**核心态**。用户程序可以执行**陷入指令（又称防管指令或trap指令）**来发起系统调用，请求操作系统提供服务。可以这么理解，用户程序执行**陷入指令**，相当于把CPU的使用权主动交给**操作系统内核程序**（CPU状态会从**用户态**进入**核心态**），之后操作系统内核程序再对系统调用请求作出相应处理。处理完成后，**操作系统内核程序**又会把CPU的使用权还给**用户程序**（即CPU状态会从**核心态**回到**用户态**）。这么设计的目的是，用户程序不能直接执行对系统影响非常大的操作，必须通过系统调用方式请求操作系统代为执行，以便保证系统的稳定性和安全性，防止用户程序**随意更改**或**访问重要的系统资源**，影响其他程序的运行
  
  + 用户通过**操作系统**运行上层程序（如系统提供的**命令解释程序**或**用户自编程序**），而这个上层 程序的运行依赖于**操作系统**底层管理程序提供服务支持，当需要管理程序服务时，系统通过**硬件中断机制**进入**核心态**，运行管理程序；也可能是程序运行出现异常情况，被动地需要管理程序的服务，这时就通过异常处理来进入**核心态**。管理程序运行结束时，用户程序需要继续运行，此时通过相应的保存的程序现场退出**中断处理程序**或**异常处理程序**，返回断点处继续执行。如下图
  
    ![image-20220711112214621](../images/image-20220711112214621.png)
  
  + 列举一些**用户态**转**核心态**的例子
  
    + 用户程序要求操作系统的服务，即**系统调用**
    + 发生一次**中断**
    + 用户程序中产生了一个**错误状态**
    + 用户程序中企图执行一条**特权指令**
    + 从**核心态**转**用户态**由一条指令实现，这条指令也是**特权指令**，一般是**中断返回**指令
  
    > 由**用户态**进入**核心态**，不仅状态需要切换，而且所用的堆栈也可能需要**用户堆栈**切换为**系统堆栈**，但这个**系统堆栈**也是属于该进程的。
  
  + **用户态**转**核心态**，会用到**访管指令**，**访管指令**是在用户态使用的，所以它**不可能是特权指令**

## 操作系统的体系结构

### 大内核和微内核

+ **大内核系统**将操作系统的主要功能模块都作为一个紧密联系的整体运行在**核心态**，从而为应用提供性能的系统服务。
+ 为解决操作系统的内核代码**难以维护**的问题，提出了**微内核**的体系结构。它将内核中最基本的功能保留在内核，将不需要在**核心态**执行的功能移到**用户态**执行，从而降低了内核的设计复杂性。移出内核的操作系统代码根据分层的原则被划分成若干服务程序，它们的执行相互独立，交互则都借助于**微内核**进行通信。
+ **微内核**结构有效地分离了**内核与服务、服务与服务**，使得它们之间的接口更加清晰，维护的代价大大降低，各部分可以独立地优化和演进，从而保证了操作系统的可靠性
+ 最大的问题是**性能**问题，因为需要频繁地在**核心态**和**用户态**之间切换，操作系统的执行开销偏大。因此有的操作系统把频繁使用的**系统服务**移回**内核**，但**体系结构**不是引起**性能下降**的主要因素，为减少**切换开销**，也可以将**系统服务**作为**运行库**链接到**用户程序**，这种体系结构称为**库操作系统**

## 总结

+ **并行性**和**并发性**的区别和联系
  + `并行性`
    + 两个或多个事件在**同一时刻**发生
  + `并发性`
    + 两个或多个事件在**同一时间间隔**发生
  + **多道程序**环境下，**并发性**指一段时间内，宏观上有多个程序同时运行，但在**单处理器**系统中，每个时刻仅能有一道程序执行，因此，**微观**上这些程序只能**分时**交替运行。但在**多处理器**系统中，**并发执行**的程序被分配到多个处理器上，实现**并行执行**
+ **特权指令**和**非特权指令**
  + **特权指令**必须在**核心态**执行，CPU在**核心态**下可以执行指令系统的全集
  + **用户态**下只能使用**非特权指令**，使用**特权指令**时，将产生**中断**以阻止用户使用
  + 从**用户态**转换为**核心态**的唯一途径是**中断**或**异常**
+ **访管指令**和**访管中断**
  + **访管指令**是一条可以在**用户态**下执行的指令，在用户程序中，因要求操作系统提供服务而有意识的使用**访管指令**，从而产生一个**中断事件（自愿中断）**，将操作系统转换为**核心态**，称为**访管中断**。**访管中断**由**访管指令**产生，程序员使用**访管指令**向操作系统请求服务
  + **访管指令**本身不是**特权指令**，基本功能是让程序拥有**自愿进管**的手段，从而引起**访管中断**
  + 处于**用户态**的用户程序使用**访管指令**时，系统根据**访管指令**的操作数执行**访管中断处理程序**，**访管中断管理程序**将按系统调用的**操作数**和**参数**转到相应的例行子程序。完成服务功能后，退出**中断**，返回到用户程序断电继续执行。

# 进程管理

![image-20220712081540195](../images/image-20220712081540195.png)

## 进程与线程

### 进程的概念和特征

+ 进程的概念

  + **多道程序**环境下，允许多个程序**并发执行**，此时它们将失去**封闭性**，并具有**间断性**和**不可再现性**的特征。为此引入了**进程**的概念，用来**描述、控制**程序的**并发执行**，实现操作系统的**并发性、共享性**。

  + 为了使参与并发执行的程序（含数据）能**独立**地运行，必须配置一个专门的数据结构，称为**进城控制块（Process Control Block，PCB）**，由**程序段、相关数据段、PCB**三部分组成了**进程映像（进程实体）**

  + **创建**进程，实质上就是创建进程映像中的**PCB**。**撤销**进程，实质上是撤销进程的**PCB**。**进程映像**是静态的，**进程**是动态的

    > **PCB**是进程存在的唯一标志

  + `进程`：进程实体的运行过程，是系统进行**资源分配、调度**的一个独立单位

+ 进程的特征
  + `动态性` **最基本的特性**
    + 进程是程序的一次执行，有着**创建、活动、暂停、终止**等过程，具有一定的**生命周期**，是动态地**产生、变化、消亡**的
  + `并发性` **重要特征**
    + 多个进程实体同时存在于**内存**中，能在**一段**时间内**同时运行**，提高**资源利用率**
  + `独立性`
    + **进程实体**是一个能**独立运行、独立获得资源、独立接受调度**的基本单位，凡未建立**PCB**的程序，都不能作为一个独立的单位参与运行
  + `异步性`
    + 由于进程的相互制约，使得进程具有执行的**间断性**，即进程按各自独立的、不可预知的速度向前推进。**异步性**会导致执行结果的**不可再现性**，为此在操作系统中必须配置相应的**进程同步机制**
  + `结构性`
    + 每个进程都配置一个**PCB**对其进行描述。从结构上看，**进程实体**是由**程序段、数据段、进程控制块**三部分组成的

### 进程的状态与转换

+ 进程通常有以下**5**种状态，前**3**种是**基本**状态
  + `运行态`
    + 进程正在处理机上运行。在**单处理机**环境下，每个时刻最多**只有一个**进程处于运行态
  + `就绪态`
    + 进程获得了除**处理机**外的一切所需资源，一旦得到处理机，便可**立即运行**。将多个处理就绪状态的进程排成一个队列，称为**就绪队列**
  + `阻塞态` **等待态**
    + 进程正在等待某一事件而**暂停运行**，如等待某资源为**可用**（不包括**处理机**）或等待输入输出完成，即使**处理机**空闲，该进程也**不能运行**
  + `创建态`
    + 进程正在被创建，尚未转到**就绪态**。创建进程通常需要多个步骤
      + 申请一个**空白PCB**，向**PCB**填写一些**控制、管理**进程的信息
      + 由系统为该进程**分配**运行时所需资源
      + 把该进程转入**就绪态**
  + `结束态`
    + 进程正在从系统中消失，可能是**进程正常结束**或其他原因中断**退出运行**，进程需要结束运行时，系统首先将该进程置为**结束态**，然后处理**资源释放、回收**
  
+ 注意区分**就绪态**与**等待态**
  + 之所以把**处理机**和**其他资源**划分开，是因为在**分时**系统的时间片轮转机制中，每个进程分到的时间片是**若干毫秒**。也就是说，**进程**得到处理机的时间**很短**且**频繁**，进程在运行过程中是**频繁**转到**就绪态**的。而**其他资源（如外设）**的**使用、分配**或某一事件的发生（如I/O操作的完成）对应的时间相对来说**很长**，转到**等待态**的次数也**相对较少**
  
+ 进程状态的**转换**
  + **就绪态** -> **运行态**
  
    + 获得**处理机**资源
  
  + **运行态** -> **就绪态**
  
    + **时间片**用完后，让出**处理机**
    + **可剥夺**的操作系统中，**更高**优先级的进程就绪时，调度程序将**正在执行**的进程转换为**就绪态**，让**更高**优先级的进程执行
  
  + **运行态** -> **阻塞态**
  
    + 进程请求**某一资源**（如外设）的**使用、分配**或**等待某一事件**的发生，如（IO操作的完成）时
    + 进程以**系统调用**的形式请求操作系统提供服务，这是一种特殊的、由运行**用户态**程序调用操作系统**内核**过程的形式
  
  + **阻塞态** -> **就绪态**
  
    + 进程等待的事件到来时，如**IO操作结束、中断结束**
  
    ![image-20220713111007884](../images/image-20220713111007884.png)
  
    > 一个进程从**运行态**变成**阻塞态**是**主动**行为，从**阻塞态**变成**就绪态**是**被动**行为，需要其他进程的协助

### 进程控制

+ 一般把**进程控制**用的程序段称为**原语**，原语的特点是执行期间**不允许中断**，是一个不可分割的基本单位

+ `进程的创建`

  + 子进程可以**继承**父进程所拥有的**资源**，子进程被撤销时，应将其从父进程获得的资源**归还**给父进程
  + 操作系统创建一个新进程的过程如下（**创建原语**）
    + 为新进程分配一个唯一的**进程标识号**，申请一个空白的**PCB**（PCB是**有限**的），PCB申请失败，则创建失败
    + 为进程分配资源，为**程序、数据、用户栈**分配必要的内存空间（在**PCB**体现）
      + 若**资源不足（如内存空间）**，并不是**创建失败**，而是处于**阻塞态**，等待内存资源
    + 初始化**PCB**，主要包括初始化**标志信息、处理机状态信息、处理机控制信息**以及设置进程的**优先级**等
    + 若进程**就绪队列**能够接纳新进程，则将新进程插入就绪队列，等待被调度运行

+ `进程的终止`

  + 引起进程终止的事件主要有

    + `正常结束`
      + 表示进程的任务已完成并准备退出运行
    + `异常结束`
      + 表示进程在运行时，发生了某种**异常**事件，使程序无法继续运行
        + 如**存储区越界、保护错、非法指令、特权指令错、运行超时、算术运算错、IO故障**等

    + `外界干预`
      + 进程应外界的请求而终止运行
        + 如**操作员/操作系统干预、父进程请求、父进程终止**

  + 操作系统终止进程的过程（**撤销原语**）

    + 根据被终止进程的**标识符**，检索**PCB**，从中读出该进程的状态
    + 若被终止进程处于**执行状态**，立即**终止**该进程的执行，将处理机资源**分配给其他进程**
    + 若该进程还有子孙进程，则将所有子孙进程终止
    + 将该进程拥有的**所有资源**，或归还给**父进程**，或归还给**操作系统**
    + 将**PCB**从所在队列（链表）中**删除**

+ `进程的阻塞和唤醒`

  + 正在执行的进程，由于期待的事件**未发生**（请求系统资源失败、等待某种操作完成、新数据尚未到达、无新工作可做），由系统**自动执行阻塞原语（Block）**，使自己由**运行态**变为**阻塞态**

  + 可见，进程的**阻塞**是进程自身的一种主动行为，也因此只有处于**运行态**的进程（获得CPU），才可能将其转为**阻塞态**。**阻塞原语**的执行过程如下

    + 找到将要阻塞进程的标识号对应的**PCB**
    + 若该进程为**运行态**，则保护其现场，将其状态转为**阻塞态**，停止运行
    + 把该**PCB**插入相应事件的等待队列，将处理机资源调度给**其他**就绪进程

  + 当**被阻塞**进程所期待的事件出现时（启动的IO操作已完成、期待的数据已到达），由有关进程（释放该IO设备的进程、或提供数据的进程）调用**唤醒原语（Wakeup）**，将等待该事件的进程唤醒，**唤醒原语**执行过程如下

    + 在该事件的**等待队列**中找到相应进程的**PCB**
    + 将其从**等待队列**中移出，并置其状态为**就绪态**
    + 把该**PCB**插入就绪队列，等待**调度程序**调度

    > **Block原语**与**Wakeup原语**是一对作用相反的原语，必须**成对使用**。**Block原语**是由被阻塞进程自我调用实现的，**Wakeup原语**是由一个与被唤醒进程合作**或**被其他相关的进程调用实现的

+ `进程切换`

  + **处理机**从一个进程的运行转到另一个进程上运行，在这个过程中，进程的运行环境产生了实质性的变化。进程切换的过程如下

    + 保存处理机**上下文**，包括**程序计数器、其他寄存器**
    + 更新**PCB**信息
    + 把进程的**PCB**移入相应的队列
      + 如就绪、在某事件阻塞等队列
    + 选择另一个进程执行，并更新其**PCB**
    + 更新内存管理的**数据结构**
    + **恢复**处理机上下文

  + **进程切换**与**处理机模式切换**是不同的，**模式切换**时，处理机逻辑上可能还在同一进程中运行。若进程因**中断、异常**进入**核心态**运行，执行完后又回到**用户态**刚被中断的程序运行，则操作系统只需恢复进程进入内核时所保存的**CPU现场**，而无需改变当前**进程**的环境信息。而**切换进程**，则当前进程的环境信息需要改变。

    > **调度**和**切换**的区别，**调度**是决定资源分配给哪个进程的行为，是一种决策行为。**切换**是实际分配的行为，是执行行为。一般来说，先资源**调度**，后进程**切换**

### 进程的组织

+ `进程控制块` **最核心**

  + 进程执行时，系统通过其**PCB**了解进程的现行状态信息，以便对其进行**控制、管理**，管理结束时，系统收回其**PCB**，该进程随之消亡。

  + **PCB**主要包括**进程描述信息、进程控制、管理信息、资源分配清单、处理机相关信息**等，详细如下

    |     进程描述信息      | 进程控制和管理信息 | 资源分配清单 | 处理及相关信息 |
    | :-------------------: | :----------------: | :----------: | :------------: |
    | 进程标识符（**PID**)  |    进程当前状态    |  代码段指针  |  通用寄存器值  |
    | 用户标识符（**UID**） |     进程优先级     |  数据段指针  |  地址寄存器值  |
    |                       |  代码运行入口地址  |  堆栈段指针  |  控制寄存器值  |
    |                       |   程序的外存地址   |  文件描述符  |  标志寄存器值  |
    |                       |    进入内存时间    |     键盘     |     状态字     |
    |                       |   处理机占用时间   |     鼠标     |                |
    |                       |     信号量使用     |              |                |

    + **进程标识符**：标志各个进程，每个进程都有唯一的标识号
    + **用户标识符**：进程归属的用户，主要为**共享、保护**服务
    + **进程当前状态**：作为**处理机**分配调度的依据
    + **资源分配清单**：说明有关内存地址空间、虚拟地址空间的状况，所打开文件的列表、使用的输入输出设备信息
    + **处理机相关信息**：处理机中各**寄存器**的值，当进程被切换时，处理机状态信息都必须保存在相应的**PCB**中，以便在进程重新执行时，能从断点继续执行

  + 组织**PCB**的常用方式有**链接方式**和**索引方式**两种

    + `链接方式`
      + 将**同一状态**的PCB链接成一个**队列**，不同状态对应不同的队列，也可把处于**阻塞态**的进程的PCB，根据**阻塞原因**的不同，排成多个阻塞队列
    + `索引方式`
      + 将**同一状态**的进程组织在一个**索引表**中，索引表的表项指向相应的**PCB**，不同状态对应不同的索引表
        + 如**就绪索引表、阻塞索引表**

+ `程序段`

  + 能被**进程调度程序**调度到CPU执行的程序代码段。注意，程序可被多个进程共享，即多个进程可以运行同一程序

+ `数据段`

  + 可以是进程对应的程序加工处理的**原始数据**，也可以是程序执行时产生的**中间、最终结果**

### 进程的通信

+ **PV**操作是低级通信方式，高级通信方式是以**较高的效率传输大量数据**的通信方式，主要有3种

  + `共享存储`

    + 通信的进程之间存在一块可直接访问的共享空间，通过对这片共享空间进行读写操作实现**进程**之间的信息交换
    + 共享存储分**两**种
      + `低级方式`：基于数据结构的共享
      + `高级方式`：基于存储区的共享
    + **操作系统**只负责为通信进程提供可共享使用的**存储空间、同步互斥工具**，**用户**需自己安排读写指令完成**数据交换**
    + **用户程序空间**一般都是独立的，进程运行期间一般不能访问**其他进程**的空间，而进程内的**线程**是自然共享进程空间的

  + `消息传递`

    + 进程间的**数据交换**是以格式化的**消息**为单位的，若通信的进程之间不存在可以直接访问的共享空间，则必须利用**操作系统**提供的消息传递方法实现**进程通信**。进程通过系统提供的**发送消息、接收消息**两个原语进行数据交换。
      + `直接通信方式`
        + 发送进程直接把**消息**发送给接收进程，并将它挂在接收进程的**消息缓冲队列**上，接收进程从**消息缓冲队列**中取得消息
      + `间接通信方式` **信箱通信方式**
        + 发送进程把**消息**发送到某个**中间实体（或信箱）**，接收进程从中间实体取得消息。该通信方式广泛应用于**计算机网络**中，相应的通信系统称为**电子邮件系统**

  + `管道通信`

    + 消息传递的一种特殊方式，所谓**管道**，是用于连接一个**读进程**和一个**写进程**以实现它们之间的通信的一个共享文件，又名**pipe**文件。

    + 为了协调双方的通信，管道机制必须提供三方面的能力：**互斥、同步、确定对方的存在**

    + **管道**也是一种文件，但是管道可以克服使用文件进行通信的**两个**问题

      + `限制管道的大小`
        + 管道是一个固定大小的缓冲区，在Linux中固定大小为**4KB**
      + `读进程也可能工作的比写进程快`
        + 当这种情况发生时，一个随后的**read()**调用将被**阻塞**，等待某些数据被写入，解决了**read()**调用返回文件结束的问题

      > 从管道**读数据**是一次性操作，数据一旦被读取，它就从管道中被抛弃，释放空间以便写更多的数据。管道只能采用**半双工通信**，即某一时刻只能单向传输。要实现父子进程双方互动通信，需要定义两个管道。

    + 管道可以理解为**共享存储**的优化和发展，因为在共享存储中，若某进程要访问共享存储空间，则必须没有**其他进程**在该共享存储空间进行**写操作**

    > PV操作是一种实现进程**互斥、同步**的有效方式，与**信号量**的处理相关，**P**表示通过的意思，**V**表示释放的意思

### **线程概念**和**多线程模型**

+ 线程的基本概念

  + 引入**进程**的目的是更好地使多道程序**并发执行**，提高**资源利用率、系统吞吐量**。引入**线程**的目的是减小程序在并发执行时所付出的**时空开销**，提高操作系统的**并发性能**
  + **线程**是进程中的一个实体，是被系统**独立调度、分派**的基本单位，自己不拥有系统资源，只拥有一点儿在运行时必不可少的资源
  + 引入**线程**后，进程的内涵发生改变，进程只作为除CPU外的**系统资源**的分配单元，而**线程**作为处理机的分配单元。

+ **线程**与**进程**的比较

  + `调度`
    + 同一进程中，**线程**的切换不会引起**进程**切换。在不同**进程**中进行**线程**切换（如从一个进程内的线程切换到另一个进程中的线程时），会引起**进程**切换
  + `拥有资源`
    + **进程**拥有资源，**线程**不拥有系统资源，有一点儿必不可少的资源，**线程**可以访问其隶属进程的系统资源
  + `并发性`
    + **进程**和**线程**都可以并发执行
  + `系统开销`
    + 创建、撤销**进程**，系统要为之**分配、回收**资源，如内存空间、IO设备。因此开销比**线程**大
    + 切换**进程**，涉及当前执行进程**CPU环境**的保存、新调度到进程**CPU环境**的设置。而切换**线程**，只需保存、设置少量**寄存器内容**，开销很小
  + `地址空间和其他资源`
    + **进程**的地址空间之间互相独立，同一**进程**的各**线程**间共享进程的资源，某**进程**内的**线程**对于其他**进程**不可见
  + `通信方面`
    + **进程**间通信（IPC）需要进程**同步、互斥**手段的辅助，以保证数据的一致性，而**线程**间可以直接读写**进程**数据段（如全局变量）来进行通信

+ **线程**的属性

  + 是一个**轻型实体**，不拥有**系统资源**，但有一个唯一的**标识符**和一个**线程控制块**，线程控制块记录了线程执行的**寄存器、栈**等现场状态
  + 不同的**线程**可以执行相同的**程序**，即同一个服务程序被不同用户调用时，操作系统把它们创建成不同的线程
  + 同一**进程**中的各个**线程**共享该**进程**所拥有的资源
  + **线程**是处理机的独立调度单位，多个线程是可以**并发**执行的。在单CPU的计算机系统中，各线程可以交替地占用CPU，若各个CPU同时为一个**进程**内的线程服务，则可缩短进程的处理时间
  + **线程**在生命周期内会经历**阻塞态、就绪态、运行态**等各种状态变化

+ **线程**的实现方式

  + `用户级线程` **（User-Level Thread， ULT）**

    + **内核**意识不到该种线程的创建、撤销、切换等
    + 通常，应用程序从**单线程**开始，在其运行的任何时刻，可以通过调用线程库中的派生例程创建新线程

  + `内核级线程` **（Kernel-Level Thread， KLT）、内核支持的线程**

    + 线程管理的所有工作由**内核**完成，应用程序没有进行线程管理的代码，只有一个到**内核级线程**的编程接口
    + **内核**为进程机器内部的每个线程维护上下文信息，调度也在**内核** 基于线程架构的基础上完成
    + 有些系统中使用**组合**方式的多线程实现。线程创建完全在用户空间中完成，线程的**调度、同步**也在应用程序中进行。一个应用程序中的多个**用户级线程**被映射到一些（小于等于用户级线程的数目）内核级线程上

    ![image-20220714111545655](../images/image-20220714111545655.png)

+ **多线程**模型

  + `多对一模型`
    + 将多个**用户级线程**映射到一个**内核级线程**，线程管理在**用户空间**完成。此模式中，**用户级线程**对操作系统不可见（即**透明**）
    + **优点**：线程管理是在**用户空间**进行的，效率比较高
    + **缺点**：一个线程在使用**内核**服务时被阻塞，整个**进程**都会被阻塞；多个线程不能**并行**地运行在**多处理机**上
  + `一对一模型`
    + 将每个**用户级线程**映射到一个**内核级线程**
    + **优点**：一个线程被阻塞后，允许另一个线程继续执行，所以并发能力强
    + **缺点**：每创建一个**用户级线程**都需要创建一个**内核级线程**与其对应，这样创建线程的开销比较大，会影响到应用程序的性能
  + `多对多模型`
    + 将n个**用户级线程**映射到m个**内核级线程**上，要求**$m \le n$**
    + **特点**：克服了**多对一**模型的**并发度不高**的缺点，克服了**一对一**模型的一个用户进程占用太多内核级线程而**开销太大**的缺点

## 处理机调度

### 调度的概念

+ 调度的基本概念

  + 对**处理机**进行分配，即从**就绪队列**中按照一定的算法公平、高效地选择一个**进程**并将处理机分配给它运行，以实现进程**并发**地执行

+ 调度的层次

  + `作业调度` **高级调度**

    + **内存、辅存**之间的调度，对于每个作业只调入一次、调出一次
    + 多道批处理系统中大多配有**作业调度**，其他系统通常不需要配置。作业调度的执行频率较**低**，通常为几分钟一次

  + `中级调度` **内存调度**

    + 提高**内存利用率、系统吞吐量**，将暂时不能运行的进程调至**外存**等待，此时的进程状态称为**挂起态**。当**具备运行条件、内存有空闲**时，由**中级调度**来决定把外存上的**就绪进程**重新调入内存，修改器状态为**就绪态**，挂在就绪队列上等待

  + `进程调度` **低级调度**

    + 按照某种方法、策略从**就绪队列**选取一个进程，将处理机分配给它。**进程调度**是最**基本**的一种调度，一般的操作系统都必须配置。**进程调度**频率很高，一般几十毫秒一次。

    ![image-20220714142625537](../images/image-20220714142625537.png)

+ 三级调度的联系

  + **作业调度**从外存的后备队列中选择一批**作业**进入内存，为它们建立**进程**，这些进程被送入**就绪队列**，**进程调度**从就绪队列中选出一个进程，把其状态改为**运行态**，把CPU分配给它。**中级调度**是为了提高内存的利用率，系统将那些暂时不能运行的进程挂起来。当内存空间宽松时，通过**中级调度**选择具备运行条件的进程，将其唤醒。
  + **作业调度**为进程活动做准备，**进程调度**使进程正常活动起来，**中级调度**将暂时不能运行的进程挂起，**中级调度**处于**作业调度、进程调度**之间
  + **作业调度**次数少，**中级调度**次数略多，**进程调度**频率最高
  + **进程调度**是最基本的，不可或缺

### 调度的时机、切换、过程

+ 进程**调度、切换**程序是操作系统**内核程序**。

+ 现代操作系统中，不能进行进程的**调度、切换**的情况有以下几种

  + `处理中断的过程中`

    + 中断处理过程复杂，实现上很难做到**进程切换**，而且**中断处理**是系统工作的一部分，逻辑上不属于某一进程，不应被剥夺处理机资源

  + `进程在操作系统内核程序临界区中`

    + 进入临界区后，需要**独占式**地访问共享数据，理论上必须加锁，以防止其他并行程序进入，在解锁前**不应**切换到其他进程运行，以加快该共享数据的**释放**

  + `其他需要完全屏蔽中断的原子操作过程中`

    + 如**加锁、解锁、中断现场保护、恢复**等原子操作。在原子过程中，连中断都要屏蔽，更不应该进行进程**调度、切换**

    > 若在上述过程中发生了引起**调度**的条件，则不能马上进行**调度、切换**，应置系统的**请求调度标志**，直到上述过程结束后才进行相应的**调度、切换**

+ 应该进行进程**调度、切换**的情况如下

  + 发生**引起调度条件、当前进程无法继续运行下去**时，可以马上调度切换。若操作系统只在这种情况下进行**进程调度**，则是**非剥夺调度**

  + **中断处理结束、自陷处理结束**后，返回被中断进程的**用户态**程序执行现场前，若置上**请求调度标志**，即可马上进行进程**调度、切换**。若操作系统支持这种情况下的运行调度程序，则实现了**剥夺**方式调度

    > **进程切换**往往在调度完成后立刻发生，它要求保存原进程当前切换点的**现场信息**，恢复被调度进程的**现场信息**。现场切换时，操作系统内核将原进程的**现场信息**推入当前进程的**内核堆栈**来保存它们，并更新堆栈指针。内核完成从**新进程**的内核栈中装入新进程的**现场信息**、更新当前运行进程空间指针、重设PC寄存器等相关工作之后，开始运行新的进程

### 进程调度方式

+ `非剥夺调度方式` **非抢占方式**
  + 当一个进程正在处理机上执行时，即使有某个更为重要的进程进入**就绪队列**，仍然让正在执行的进程继续执行，直到该进程**完成**或**发生某种事件**而进入**阻塞态**时，才把处理机分配给更为重要或紧迫的进程
  + 一旦把CPU分配给一个进程，该进程就会保持CPU直到**终止**或转换到**等待态**。**优点**是实现简单、系统开销小，适用于大多数的批处理系统，但不能用于**分时系统、大多数的实时系统**
+ `剥夺调度方式` **抢占方式**
  + 当一个进程正在处理机上执行时，若有某个更为重要的进程需要使用处理机，则立即**停止**正在执行的进程，将处理机分配给这个更重要的进程
  + 提高**系统吞吐率、响应效率**，但**剥夺**不是一种任意性行为，必须遵循一定的原则，主要有**优先权、短进程优先、时间片原则**等

### 调度的基本准则

+ `CPU利用率`
  + 尽可能使CPU保持**忙**状态
+ `系统吞吐量`
  + **单位时间**内CPU完成作业的数量。
+ `周转时间`
  + 从**作业提交**到**作业完成**所经历的时间，是**作业等待、就绪队列排队、处理机运行、进行输入输出操作**所花费时间的总和
  + **周转时间 = 作业完成时间 - 作业提交时间**
  + **带权**周转时间是**作业周转时间**与**作业实际运行时间**的比值
    + **带权周转时间 = 作业周转时间 / 作业实际运行时间**
+ `等待时间`
  + 进程处于**等处理机状态**的时间之和
    + **处理机调度算法**实际上不影响**作业执行、输入输出操作时间**，只影响作业在**就绪队列**中等待所花的时间。因此，衡量一个调度算法的优劣，只需简单考查**等待时间**
+ `响应时间`
  + 从**用户提交请求**到**系统首次产生响应**所用的时间。在交互式系统中，一般采用**响应时间**而不是**周转时间**作为衡量调度算法的重要准则。
  + 从用户角度看，调度策略应尽量**降低响应时间**

### 典型的调度算法

+ `先来先服务（FCFS）`调度算法

  + **最简单**的调度算法，可用于**作业调度、进程调度**

    + **作业调度**中，从**后备作业队列**中选**最先**进入该队列的一个或几个作业，调入内存，分配资源，创建进程，放入就绪队列
    + **进程调度**中，从**就绪队列**选择**最先**进入该队列的进程，分配处理机

    ![image-20220714161058333](../images/image-20220714161058333.png)

  + 属于**不可剥夺**算法，对所有作业都公平，长作业先到达，会使后面许多短作业等待长时间，因此不能作为**分时系统、实时系统**的主要调度策略

  + 被**结合**在其他调度策略中使用

    + 在使用**优先级**作为调度策略的系统中，对多个具有**相同优先级**的进程按FCFS原则处理

  + **特点**是算法简单、但效率低。对**长作业**有利，不利于**短作业**（相对于**SJF、高响应比**），有利于**CPU**繁忙型作业，不利于**IO**繁忙型作业。

+ `短作业优先（SJF）`调度算法

  ![image-20220714162342375](../images/image-20220714162342375.png)

  + **缺点**

    + 对**长作业**不利，长作业**周转时间**会增加。可能导致长期不被调度（**饥饿**现象，区分**死锁**，前者是调度策略问题，后者是**系统环形等待**）
    + 未考虑作业的**紧迫程度**
    + 作业的长短只是根据**用户所提供的估计执行时间**而定，不一定能真正做到短作业优先调度

    > **SJF**调度算法的**平均等待时间、平均周转时间**最少

+ `优先级`调度算法

  + 可用于**作业调度、进程调度**
  + 根据新的更高优先级进程能否**抢占**正在执行的进程，该调度算法可分如下**两**种
    + `非剥夺式优先级`调度算法
      + 让正在运行的进程**继续**执行，直到由于自身的原因而主动让出处理机（**任务完成、或等待事件**）
    + `剥夺式优先级`调度算法
      + 立即暂停正在执行的进程
  + 根据进程创建后其**优先级**是否可以改变，可分为**两**种
    + `静态优先级`
      + **优先级**在**创建进程**时确定，在运行期间不变。确定优先级的主要依据有**进程类型、进程对资源的要求、用户要求**
    + `动态优先级`
      + 进程运行时动态调整优先级，调整优先级的依据有**进程占有CPU时间的长短、就绪进程等待CPU时间长短**
    + 一般来说，**进程优先级**的设置可以参照以下原则
      + **系统进程 > 用户进程**
      + **交互型进程 > 非交互型进程，前台进程 > 后台进程**
      + **IO型进程 > 计算型进程**
        + IO设备的处理速度比CPU慢得多，因此将IO型进程的优先级设置得更高，更有可能让IO设备尽早开始工作，进而提升系统的整体效率

+ `高响应比优先`调度算法

  + 用于**作业调度**，对**FCFS、SJF**的一种综合平衡。在每次进行作业调度时，先计算后备作业队列中每个作业的**响应比**，选出最高的作业运行
    $$
    响应比R_p = \frac{等待时间+要求服务时间}{要求服务时间}
    $$

    + 作业的等待时间相同时，要求服务时间**越短**，响应比**越高**，利于**短作业**
    + 要求服务时间相同时，等待时间**越长**，响应比**越高**，因此实现的是**先来先服务**，对于长作业也是，因此克服了**饥饿状态**

+ `时间片轮转`调度算法

  + 适用于**分时系统**
  + **时间片**的大小对系统性能影响很大，若时间片足够大，以至于所有进程都能在一个时间片内执行完毕，则算法退化成**先来先服务**调度算法。若时间片很小，则处理机将频繁地在进程间切换，使处理机开销增大
  + **时间片**的长短通常由以下因素确定：**系统的响应时间、就绪队列中的进程数目、系统的处理能力**

+ `多级反馈队列`调度算法

  + 是**时间片轮转**调度算法和**优先级**调度算法的综合发展，通过动态调整进程**优先级、时间片大小**，该算法可以兼顾多方面的系统目标

    ![image-20220714165445316](../images/image-20220714165445316.png)

  + **实现思想**

    + 设置多个**就绪队列**，赋予不同的**优先级**，第**1**级队列优先级**最高**
    + 赋予各个队列中进程执行**时间片**的大小各不相同。优先级**越高**的队列，每个进程的运行时间片**越小**
    + 一个新进程进入内存后，放入**第1级队列末尾**，按**FCFS**原则排队等待调度。当轮到该进程执行时，如能在该时间片内完成，便可准备撤离系统；若未完成，该**进程**进入**第2级队列末尾**，再同样按照**FCFS**等待调度执行，以此轮转
    + 仅当**第1级队列**为空，调度程序才调度**第2级队列**中的进程，以此类推。若处理机正在执行**第i级队列**中的某进程时，有新进程进入**优先级较高**的队列，则新进程将**抢占**正在运行进程的处理机，即由调度程序把正在运行的进程放回**第i级队列**的末尾，把处理机分配给新进程

  + **优点**

    + `终端型作业用户`
      + **短作业**优先
    + `短批处理作业用户`
      + **周转时间**较短
    + `长批处理作业用户`
      + 经过前面几个队列得到部分执行，不会长期得不到处理

## 进程同步

### 进程同步的基本概念

+ `临界资源`

  + **一次**仅允许**一个进程**使用的资源

    + 许多**物理设备**都属于临界资源。许多**变量、数据**等都可以被若干进程共享，也属于临界资源

  + 对**临界资源**的访问，必须互斥地进行，在每个进程中，访问临界资源的那段代码称为**临界区**，为了保证**临界资源**的正确使用，可把访问临界资源的过程分为**4**部分

    + `进入区`

      + 先检查可否进入临界区，能进，则设置**正在访问临界区**的标志，以阻止其他进程同时进入临界区

    + `临界区`

      + 进程中访问**临界资源**的那段代码，称**临界段**

    + `退出区`

      + 将**正在访问临界区**的标志清除

    + `剩余区`

      + 代码中的其余部分

      ```c
      do {
          entry section;
          critical section;
          exit section;
          remainder section;
      } while (true)
      ```

+ `同步` **制约关系**
  + 为完成某种任务而建立**两个或多个**进程，因为需要协调这些进程的**工作次序**而**等待、传递信息**所产生的制约关系
+ `互斥` **间接制约关系**
  + 当一个进程进入**临界区**使用**临界资源**时，另一个进程必须等待，直到该进程退出临界区
  + 为禁止两个进程同时进入**临界区**，同步机制应遵循以下准则
    + `空闲让进`
      + **临界区**空闲时，可以允许一个请求进入临界区的**进程**立即进入临界区
    + `忙则等待`
      + 已有进程进入**临界区**时，其他试图进入**临界区**的进程必须等待
    + `有限等待`
      + 对请求访问的进程，应保证能在有限时间内进入**临界区**
    + `让权等待`
      + 当进程不能进入**临界区**时，应立即释放处理器，防止进程**忙等待**

### 实现**临界区**互斥的基本方法

+ 软件实现方法

  + `单标志法`

    + 设置一个公用整型变量turn，用于指示被允许进入**临界区**的**进程编号**，若turn=0，允许$P_0$进程进入临界区。但两个进程必须**交替**进入临界区，若某个进程不再进入临界区，则另一个进程也将无法进入临界区。（违背**空闲让进**）
      + 只有一个公用变量，且某个进程出来时并不**重置**该公用变量，需要依赖其他进程改变该公用变量，以让该进程能重新进入

  + `双标志法先检查`

    + 每个进程访问临界区资源之前，先查看临界资源是否**正被访问**，若正被访问，该进程需等待；否则，进程才进入自己的临界区。为此，设置一个数据**flag[i]**，如第**i**个元素值为**FALSE**，表示**$P_i$**进程未进入临界区，值为**TRUE**，表示进入临界区。

    + **优点**是不用交替进入，可连续使用。**缺点**是两个进程可能同时进入临界区。

      ![image-20220714191407175](../images/image-20220714191407175.png)

  + `双标志法后检查`

    + 算法二先检测**对方**的进程状态标志，再置自己的标志，由于在**检测、放置**中可插入另一个进程到达时的检测操作，会造成两个进程在分别检测后**同时**进入临界区。为此，该算法先将自己的标志设置为**TRUE**，再检测对方的状态标志，若对方标志为**TRUE**，则进程等待；否则进入**临界区**

      ![image-20220714192200840](../images/image-20220714192200840.png)

    + 两个进程几乎同时都想进入**临界区**时，分别将自己的标志值flag设置**TRUE**，并同时检测对方的状态（执行while语句），发现对方也要进入**临界区**时，双方互相谦让，导致都无法进入，形成**饥饿**现象

  + `Peterson's Alogrithm`

    + 为了防止两个进程为进入**临界区**而无限期等待，又设置了变量turn，每个进程在先设置自己的标志后，再设置turn标志。

      ![image-20220714192703592](../images/image-20220714192703592.png)

    + 利用flag解决**临界资源**的互斥访问，利用turn解决**饥饿**现象

+ 硬件实现方法

  + `中断屏蔽方法`

    + 禁止一切中断发生，或称之为**屏蔽中断、关中断**。因为CPU只在发生中断时引起**进程切换**，因此**屏蔽中断**能够保证当前运行的进程让**临界区**代码顺利地执行完，进而保证互斥的正确实现，然后执行**开中断**，即**关中断 -> 临界区 -> 开中断**
    + 这种方法限制了处理机**交替**执行程序的能力，因此执行效率明显**降低**。对内核来说，在它执行更新变量或列表的几条指令期间，**关中断**是很方便的，但将**关中断**的权利交给用户则很不明智，若一个进程**关中断**后不再**开中断**，则系统可能会因此终止

  + `硬件指令方法`

    + **TestAndSet**指令：这条指令是**原子操作**，即执行该代码时不允许被中断。其功能是读出指定标志后把该标志设置为**真**。

    + 可以为每个**临界资源**设置一个共享布尔变量**lock**，表示资源的两种状态：**true**表示正被占用，初值为**false**。在进程访问临界资源之前，利用**TestAndSet**检查和修改标志**lock**；若有进程在临界区，则重复检查，直到进程退出。

    + **Swap**指令：该指令的功能是交换两个字（字节）的内容

      > 以上对**TestAndSet**和**Swap**指令的描述仅是功能实现，而非软件实现的定义。事实上，它们是由硬件逻辑直接实现的，不会被中断

    + 应为每个**临界资源**设置一个共享布尔变量**lock**，初值为false；在每个进程中再设置一个局部布尔变量**key**，用于与**lock**交换信息。在进入**临界区**前，先利用**Swap**指令交换**lock**与**key**的内容，然后检查**key**的状态；有进程在**临界区**时，重复交换和检查过程，直到进程退出。

    + **优点**是适用于**任意数目**的进程，不管是**单处理机、多处理机**；简单、容易验证其正确性；支持进程内有多个临界区，只需为每个临界区设置一个布尔变量

    + **缺点**是进程等待进入**临界区**时要耗费处理时间，不能实现**让权等待**。从等待进程中随机选择一个进入临界区，有的进程可能一直选不上，从而导致**饥饿**现象

### 信号量

+ 信号量机制是一种功能较强的机制，可用来解决**互斥与同步**问题，只能被两个标准原语**wait（S）、signal（S）**访问，也可记为**P操作**和**V操作**

+ **原语**指完成某种功能且不被分割、不被中断执行的操作序列，通常可由**硬件**实现。原语功能不被中断执行的特性在**单处理机**上可由软件通过**屏蔽中断**方法实现

+ **整型信号量**

  + 一个用于表示**资源数目**的整型量S，该机制并未遵循**让权等待**准则，而是使进程处于**忙等**状态

+ **记录型信号量**

  + 不存在**忙等**现象的进程同步机制。除需要一个用于代表资源数目的整型变量value外，再增加一个**进程链表L**，用于链接所有等待该资源的进程。当资源已分配完毕，进程应调用**block**原语，进行自我阻塞，放弃处理机，并插入资源的等待队列，即该机制遵循了**让权等待**准则
  + 当进程释放一个资源，是系统中可供分配的资源数**增1**，但是资源数value依然**value <= 0**，表示在队列中仍有等待该资源的进程被阻塞，因此还应调用**wakeup**原语，将队列中的第一个等待进程唤醒

+ 利用信号量实现**同步**

  ![image-20220714202830579](../images/image-20220714202830579.png)

+ 利用信号量实现**进程互斥**

  ![image-20220714202911856](../images/image-20220714202911856.png)

  ![image-20220714202921138](../images/image-20220714202921138.png)

+ 利用信号量实现**前驱**关系

  ![image-20220714203134304](../images/image-20220714203134304.png)

  + 为使各程序段能正确执行，应设置若干初始值为**0**的信号量。例如，为保证**$S_1 \rightarrow S_2，S_1 \rightarrow S_3$**的前驱关系，应分别设置信号量a1，a2。同样，其他程序段类似

    ![image-20220714203359636](../images/image-20220714203359636.png)

    ![image-20220714203405886](../images/image-20220714203405886.png)

+ 分析进程**同步**和**互斥**问题的方法步骤

  + **关系分析**
    + 找出问题中的进程数，分析它们之间的**同步、互斥**关系。
  + **整理思路**
    + 找出解决问题的关键点，并根据做过的题目找出求解的思路。根据进程的操作流程确定**P操作、V操作**的大致顺序
  + **设置信号量**
    + 根据前面两步，设置需要的**信号量**，确定**初值**，完善整理

### 管程

+ 管程的定义
  + 代表共享资源的**数据结构**，以及由对该**共享数据结构**实施操作的一组**过程**所组成的**资源管理程序**，这组操作能**同步进程、改变管程中的数据**
  + 管程由**4**部分组成
    + 管程的**名称**
    + 局部于管程内部的**共享结构数据**说明
    + 对该数据结构进行操作的一组**过程**（或**函数**）
    + 对局部于管程内部的**共享数据**设置初始值的语句
  + 类比**面向对象**开发，管程很像一个**类**
    + **管程把对共享资源的操作封装起来**
      + 管程内的**共享数据结构**只能被**管程**内的过程所访问
      + 一个进程只有通过调用**管程**内的过程才能进入管程访问**共享资源**
    + **每次仅允许一个进程进入管程，从而实现进程互斥**
+ 条件变量
  + 当一个进程进入**管程**后被阻塞，直到阻塞的原因解除时，在此期间，如果该进程不释放**管程**，那么其他进程无法进入**管程**。为此，将**阻塞原因**定义为**条件变量condition**。
  + 通常，一个进程被阻塞的原因可以有多个，因此在管程中设置了多个**条件变量**。每个条件变量保存了一个**等待队列**，用于记录因该**条件变量**而阻塞的所有进程，对**条件变量**只能进行两种操作，即**wait、signal**
    + **x.wait**
      + 当**x**对应的条件不满足时，正在调用管程的进程调用**x.wait**将自己插入**x**条件的等待队列，并释放**管程**。此时**其他**进程可以使用该管程。
    + **x.signal**
      + **x**对应的条件发生了变化，则调用**x.signal**，唤醒一个因**x**条件而阻塞的进程
  + **条件变量** VS **信号量**
    + **相似点**：条件变量的**wait/signal**操作类似于信号量的**P/V**操作，可以实现进程的**阻塞/唤醒**
    + **不同点**：条件变量是**没有值**的，仅实现了**排队等待**功能；而信号量是**有值**的，反映了**剩余资源数**，而在管程中，**剩余资源数**用**共享数据结构**记录

### 经典同步问题

+ 生产者-消费者问题
+ 哲学家进餐问题

## 死锁

### 死锁的概念

+ 定义

  + 多个进程因**竞争资源**而造成的一种僵局（互相等待），若无外力作用，这些进程将无法向前推进

+ 产生原因

  + `系统资源的竞争`

    + 只有对**不可剥夺资源**的竞争才可能产生死锁，对**可剥夺资源**的竞争不会引起死锁

  + `进程推进顺序非法`

    + 进程运行过程中，**请求、释放**资源的顺序不当，同样会导致死锁。
    + **信号量**使用不当也会造成死锁

  + `死锁产生的必要条件`

    + **互斥条件**

      + 进程要求对所分配的资源进行**排他性控制**，即一段时间内某资源仅为一个进程所占有

    + **不剥夺条件**

      + 进程所获得的资源在**未使用完**之前，不能被其他进程强行夺走，只能主动释放

    + **请求并保持条件**

      + 进程已经保持了**至少一个**资源，但是又提出了**新**的资源请求，而该资源已被**其他**进程占用，此时请求进程被阻塞，但对自己获得的资源保持不放

    + **循环等待条件**

      + 存在一种进程资源的**循环等待链**，链中每个进程已获得的**资源**同时被链中下一个进程所请求。

      > 直观上看，**循环等待条件**似乎和**死锁**的定义一样，其实不然，按**死锁**定义构成**等待环**所要求的条件更严，它要求$P_i$等待的资源必须由$P_{i+1}$来满足，而**循环等待条件**无此限制。

  + 如下所示，资源分配图**含圈**而不一定造成**死锁**的原因是，**同类资源数大于1**，但若系统中每类资源都只有一个资源，则**含圈**就变成了系统出现**死锁**的充要条件

    ![image-20220714211807014](../images/image-20220714211807014.png)

    > 注意区分**不剥夺条件**和**请求并保持条件**

### 死锁的处理策略

+ 为使系统不发生**死锁**，必须破环死锁的**4**个必要条件之一；或允许死锁产生，但当死锁发生时，能检测出死锁，并有能力实现恢复

+ `死锁预防`

  + 设置**限制条件**，破坏死锁产生的4个必要条件

+ `避免死锁`

  + 在资源的**动态分配过程**中，用某种方法防止系统进入**不安全状态**，从而避免死锁

+ `死锁的检测及解除`

  + 不采取任何**限制性措施**，允许发生死锁。通过系统检测及时检测出死锁的发生，然后采取措施解除

+ **思索处理策略**的比较

  |              |                       资源分配策略                       |               各种可能模式               |                     优点                     |                             缺点                             |
  | ------------ | :------------------------------------------------------: | :--------------------------------------: | :------------------------------------------: | :----------------------------------------------------------: |
  | **死锁预防** |                    保守，宁可资源闲置                    | 一次请求所有资源，资源剥夺，资源按序分配 |     适用于突发式处理的进程，不必进行剥夺     | 效率低可，进城初始化时间延长；剥夺次数过多；不便灵活申请新资源 |
  | **死锁避免** | 是**预防**和**检测**的折中，在**运行时**判断是否可能死锁 |          寻找可能的安全允许顺序          |                 不必进行剥夺                 |         必须知道将来的资源需求；进程不能被长时间阻塞         |
  | **死锁检测** |                 宽松，只要允许就分配资源                 |         定期检查死锁是否已经发生         | 不延长进程初始化时间，允许对死锁进行现场处理 |                  通过剥夺解除死锁，造成损失                  |

### 死锁预防

+ 破坏`互斥`条件
  + 允许系统资源都能**共享**使用时，系统不会进入死锁状态。但有些资源不能同时访问，所以不太可行
+ 破坏`不剥夺`条件
  + 当一个已**保持**了某些不可剥夺资源的进程**请求**新的资源而得不到满足时，它必须**释放**已经保持的所有资源，待以后需要时再**重新申请**
  + 这种方法常用于**状态易于保存、恢复**的资源，如CPU的寄存器、内存资源，一般不能用于**打印机**之类的资源
+ 破环`请求并保持`条件
  + 采用**预先静态分配**方法，即进程在运行前**一次申请**完它所需要的全部资源，在它的资源**未满足**前，不让其运行。一旦投入运行，这些资源一直归它所有，不再提出**其他**资源请求
  + **优点**是实现简单
  + **缺点**是系统资源被严重浪费，有些资源可能仅在**运行初期**或**运行快结束**时才使用，甚至根本不使用。而且还会导致**饥饿**现象，由于个别资源长期被其他进程占用时，将致使等待该资源的进程迟迟不能开始运行。
+ 破坏`循环等待`条件
  + 采用**顺序资源分配**法，给系统中的资源**编号**，规定每个进程必须按**编号**递增的顺序请求资源，同类资源一次申请完。
    + 只要进程提出申请分配资源$R_i$，则该进程以后的资源申请中就只能申请编号大于$R_i$的资源
  + **缺点**
    + **编号**必须相对稳定，这就限制了新类型设备的增加
    + 也经常会发生作业使用资源的**顺序**与系统规定**顺序**不同的情况，造成资源的浪费
    + 按规定次序申请资源的方法，也必然会给用户的编程带来麻烦

### 死锁避免

+ `系统安全状态`

  + 允许进程动态地申请资源，但系统在进行资源分配之前，应先计算此次分配的**安全性**。若此次分配不会导致系统进入**不安全状态**，则允许**分配**；否则让进程**等待**
  + **安全状态**是指系统能按某种进程**推进顺序**为每个进程分配其所需的资源，直至满足某个进程对资源的最大需求，使每个进程都可顺序完成。此时称该**推进顺序**为**安全序列**。若系统无法找到一个安全序列，则称系统处于不安全状态。
  + 并非所有的**不安全状态**都是**死锁状态**，但当系统进入**不安全状态**后，便可能进入**死锁状态**；反之，只要系统处于**安全状态**，系统便可便避免进入**死锁状态**

+ `银行家算法`

  + 进程运行之前，先声明对各种资源的**最大需求量**

  + 当进程在执行中继续申请资源时，先**测试**该进程**已占用的资源数**与**本次申请的资源数**之和是否超过该进程声明的**最大需求量**

    + 若**超过**则拒绝分配资源
    + 若**未超过**则再测试系统**现存的资源**能否满足该进程**尚需的最大资源量**
      + 若能**满足**，则按当前的**申请量**分配资源
      + 否则**推迟分配**

  + **数据结构**描述

    + **可利用资源向量 Available**

      + 含有**m**个元素数组，其中每个元素代表一类**可用的资源数目**。**Available[j] = K**表示系统中现有$R_j$类资源K个

    + **最大需求矩阵 Max**

      + **$n\times m$**矩阵，定义系统中**n**个进程中的每个进程对**m**类资源的最大需求。简单来说，一行代表一个**进程**，一列代表一类**资源**。**Max[i, j]=K**表示进程**i**需要**$R_j$**类资源的最大数目为**K**。

    + **分配矩阵 Allocation**

      + **$n \times m$**矩阵，定义系统中每类资源当前**已分配**给每个进程的**资源数**。**Allocation[i, j] = K**表示进程**i**当前已分得**$R_j$**类资源的数目为**K**

    + **需求矩阵 Need**

      + **$n \times m$**矩阵，表示每个进程接下来最多还需要多少资源。**Need[i, j] = K**表示进程**i**还需要**$R_i$**类资源的数目为**K**

    + 三个矩阵间存在下述关系
      $$
      Need = Max - Allocation
      $$

      + 一般情况下，在**银行家算法**题目中，**Max**矩阵和**Allocation**矩阵是已知条件，而求出**Need**矩阵是解题第一步

+ `安全性算法`
  + 设置**工作向量Work**，有**m**个元素，表示系统中的**剩余可用资源数目**。在执行安全性算法开始时，**Work=Available**
    1. 初始时，**安全序列**为空
    2. 从**Need**矩阵中，找出符合下面条件的行
       + 该行对应的进程不在**安全序列**中，而且该行**小于等于**Work向量
         + **找到**后，把对应进程加入**安全序列**
         + **找不到**，则执行步骤**4**
    3. 进程$P_i$进入**安全序列**后，可顺利执行，直至完成，并释放分配给它的资源，因此应执行**Work = Work + Allocation[i]**，其中**Allocation[i]**表示进程$P_i$代表的在Allocation矩阵中对应的行，返回步骤**2**
    4. 若此时**安全序列**中已有**所有**进程，则系统处于**安全状态**，否则系统处于**不安全状态**

### 死锁检测和解除

+ 资源分配图

  + **系统死锁**可利用**资源分配图**来描述

  + **圆圈**代表一个进程，**框**代表一类资源。由于**一种类型**的资源可能有多个，因此用框中的一个**圆**代表一类资源中的一个。

  + **进程**到**资源**的有向边称为**请求边**

    + 表示该进程申请**一个单位**的该类资源

  + **资源**到**进程**的边称为**分配边**

    + 表示该类资源已有**一个**分配了该进程

    ![image-20220715094159414](../images/image-20220715094159414.png)

+ 死锁定理

  + 在**资源分配图**中，找出既不**阻塞**又不**孤点**的进程P

    + 即找出**一条有向边**与它相连，且该有向边对应的资源的**申请数量**小于等于**系统中已有的空闲资源数量**。若**所有**连接该进程的边均满足上述条件，则这个进程能继续运行直至完成，然后**释放**它所占有的所有资源

  + **消去**它所有的**请求边**和**分配边**，使之称为孤立的结点

  + 若能消去图中所有的边，则称该图是可**完全简化**的

    ![image-20220715111237482](../images/image-20220715111237482.png)

  + 系统状态为**死锁**的条件是**当且仅当**系统状态的资源分配图是**不可完全简化**的，该条件为**死锁定理**

+ 死锁**解除**

  + `资源剥夺法`
    + **挂起**一部分死锁进程，抢占它的资源，把资源分配给其他的**死锁进程**
      + 应防止**被挂起**的进程长时间得不到资源而处于**资源匮乏**的状态
  + `撤销进程法`
    + 强制**撤销**部分甚至全部**死锁进程**并剥夺这些进程的资源。撤销的原则可以按**进程优先级**和**撤销进程代价**的高低进行
  + `进程回退法`
    + 让**一个或多个**进程回退到**足以回避死锁**的地步，进程回退时，**自愿释放**资源而非**被剥夺**。
    + 要求系统保持进程的历史信息，设置还原点

## 总结

+ 为什么要引入**进程**
  + 为了深刻描述程序**动态执行过程的性质**以更好地支持和管理**多道程序的并发执行**
+ 什么是**进程**？由什么组成
  + **进程**是一个具有独立功能的**程序**关于某个数据集合的一次运行活动。可以**申请、拥有**系统资源，是一个动态的概念，是一个活动实体。通过**程序计数器的值、处理寄存器的内容**来表示
  + 进程实体由**程序段、数据段、PCB**三部分构成
+ 为什么要进行**处理机调度**？
  + 可在运行进程等待外部设备时，把处理机调度给其他进程，提高**处理机利用率**

+ 为什么会产生**死锁**？产生**死锁**有什么条件？
  + **两个或以上**进程占有自身的资源并请求对方的资源时，会导致每个进程都无法向前推进，这就是**死锁**
  + 死锁的**必要条件**
    + `互斥条件`
      + 进程要求分配的资源是**排他性**的，最多只能同时供一个进程使用

    + `不剥夺条件`
      + 进程在使用完资源之前，资源不能被**强制夺走**

    + `请求并保持条件`
      + 进程**占有自身**本来拥有的资源并**要求**其他资源

    + `循环等待条件`
      + 存在一种进程资源的**循环等待链**

+ 解决死锁的**办法**
  + `预防死锁`
    + 设立**限制条件**，破坏死锁的**必要条件**，让死锁无法发生

  + `避免死锁`
    + 在动态分配资源的过程中，用一些算法**防止系统进入不安全状态**，从而避免死锁

  + `死锁的检测与解除`
    + 死锁产生前**不采取任何措施**，只检测当前系统有没有发生**死锁**，若有，采取措施解除

+ **银行家算法**的工作原理
  + 主要思想是**避免系统进入不安全状态**。在每次进行资源分配时，它首先检查系统是否有足够的**资源**满足要求，若有则先进行分配，并对分配后的新状态进行**安全性检查**。若**新状态**安全，则正式**分配**上述资源，否则**拒绝**分配上述资源。


# 内存管理

## 内存管理概念

### 内存管理的基本原理和要求

+ `内存空间的分配与回收`

  + 操作系统完成**主存储器**空间的分配、管理，使程序员拜托存储分配的麻烦，提高编程效率

+ `地址转换`

  + 多道程序环境下，程序中的**逻辑地址**与内存中的**物理地址**不可能一致，因此，存储管理必须提供**地址变换功能**，把**逻辑地址**转换成相应的**物理地址**

+ `内存空间的扩充`

  + 利用**虚拟存储技术、自动覆盖技术**，从逻辑上扩充内存

+ `存储保护`

  + 保证各道作业在**各自的存储空间**内运行，互不干扰

+ 进程运行的**基本原理**

  + `程序装入和链接`

    + 创建**进程**首先要将**程序、数据**装入内存。将**用户源程序**变为可在内存中执行的程序，通常需要以下几个步骤

      + `编译`

        + 由**编译程序**将用户**源代码**编译成若干目标**模块**

      + `链接`

        + 由**链接程序**将编译后的一组目标**模块**及所需的库函数**链接**在一起，形成一个完整的装入模块

      + `装入`

        + 由**装入程序**将装入模块装入内存运行

        ![image-20220715154259219](../images/image-20220715154259219.png)

    + 程序的**链接**有以下三种方式

      + `静态链接`
        + 程序运行之前，先将各目标**模块**及它们所需的库函数链接成一个完整的**可执行程序**，以后不再拆开
      + `装入时动态链接`
        + 将用户源程序编译后得到的一组目标**模块**，在装入内存时，采用**边装入边链接**的方式
      + `运行时动态链接`
        + 对某些目标模块的链接，是在程序执行中需要该目标模块时才**进行的**。
        + **优点**是便于修改、更新，便于实现对目标模块的**共享**

    + 内存装入模块装入内存的**三**种方式

      + `绝对装入`
      
        + 知道程序将驻留在内存的某个位置，则产生**绝对地址**的目标代码
        + 由于程序中的**逻辑地址与实际内存地址**完全相同，因此不需要对**程序和数据的地址**进行修改
        + 只适用于**单道程序环境**
        + 程序中使用的**绝对地址**，可在**编译、汇编**时给出，也可由程序员直接赋予
          + 通常程序中采用**符号地址**，编译或汇编时再转为**绝对地址**
      
      + `可重定位装入`
      
        + **多道**程序环境下，多个目标模块的**起始地址**通常都从**0**开始，程序中的其他地址都是相对于**起始地址**的
        + 装入时，对目标程序中的**指令和数据**的修改过程称为**重定位**
          + **地址变换**通常是在装入时一次完成的，所以又称**静态重定位**
          + **静态重定位**的特点是，一个作业装入内存时，必须给它分配要求的**全部内存空间**，若没有足够的内存，则不能装入该作业。此外，作业一旦进入内存，整个运行期间就不能在内存中**移动**，也不能再申请内存空间
      
      + `动态运行时装入` **动态重定位**
      
        + 程序在内存中若发生移动，则需要采用**动态装入方式**。
      
        + 装入程序把装入模块装入内存后，不立即把装入模块的**相对地址**转换为**绝对地址**，而是推迟到程序真正要执行的时候才进行。因此，装入内存后，所有的地址均为**相对地址**，这种方式需要一个**重定位寄存器**的支持
      
        + **特点**是：可以将程序分配到不连续的存储区中，在程序运行之前可以只装入它的**部分代码**即可投入运行，之后在程序运行期间，根据需要**动态申请分配内存**，便于**程序段**的共享，可以向用户提供一个比存储空间大得多的地址空间
      
          ![image-20220716160309460](../images/image-20220716160309460.png)
  
  + `逻辑地址空间与物理地址空间`
  
    + 编译后，每个目标模块都从**0**号单元开始编址，这称为目标模块的**相对地址**（或**逻辑地址**）
    + 当**链接程序**将各个模块链接成一个完整的可执行目标程序时，**链接程序**顺序依次按各个模块的**相对地址**构成统一的从**0**号单元开始编址的**逻辑地址空间**。
    + 不同**进程**可以有相同的**逻辑地址**，因为相同的**逻辑地址**可以映射到主存的不同位置
    + **物理地址空间**是指内存中物理单元的集合，是**地址转换**的最终地址，进程在运行时**执行指令**和**访问数据**，最后都要通过**物理地址**从主存中存取。当**装入程序**将可执行代码装入内存时，必须通过**地址转换**将**逻辑地址**转换成**物理地址**，这个过程称为**地址重定位**
  
  + `内存保护`
  
    + 内存分配前，需要保护**操作系统**不受用户进程的影响，同时保护**用户进程**不受其他用户进程的影响。**内存保护**可采取两种方法
  
      + 在CPU中设置一对**上、下限寄存器**，存放用户作业在**主存**中的下限与上限地址，每当CPU要访问一个地址时，分别和两个寄存器的值相比，判断有无**越界**
  
      + 采用**重定位寄存器**（或**基址寄存器**）和**界地址寄存器**（或**限长寄存器**）来实现这种保护。**重定位寄存器**含**物理地址**的最小值，**界地址寄存器**含**逻辑地址**的最大值。每个**逻辑地址**值必须小于**界地址寄存器**；内存管理机构动态地将**逻辑地址**与**界地址寄存器**进行比较，若未发生**地址越界**，则加上**重定位寄存器**的值后映射成**物理地址**，再送交**内存单元**
  
        ![image-20220716161422449](../images/image-20220716161422449.png)
  
    + 实现**内存保护**需要**重定位寄存器**和**界地址寄存器**，因此要注意两者区别。**重定位寄存器**用来**加**的，**逻辑地址**加上**重定位寄存器**的值就能得到**物理地址**；**界地址寄存器**是用来**比**的，通过比较**界地址寄存器**的值与**逻辑地址**的值来判断是否**越界**

### 连续分配管理方式

+ `单一连续分配`

  + 内存在此方式下分为**系统区、用户区**，**系统区**仅供操作系统使用，通常在**低地址**部分；**用户区**为用户提供的、除**系统区**之外的内存空间
  + 这种方式不需要**内存保护**，因为内存中永远只有一道程序，肯定不会因**越界**影响其他程序
  + **优点**是简单、无外部碎片，可以采用覆盖技术，不需要额外的技术支持
  + **缺点**是只能用于单用户、单任务的操作系统中，有内部碎片，存储器的利用率极低

+ `固定分区分配`

  + **最简单**的一种多道程序存储管理方式，将**用户内存空间**划分为若干**固定大小**的区域，每个分区只能装入一道作业。当有**空闲分区**时，便可再从外存的**后备作业队列**中选择适当大小的作业装入该分区，如此循环

  + **固定分区分配**有两种划分分区的方法

    + `分区大小相等`
      + 用于利用**一**台计算机去控制**多**个相同对象的场合，缺乏**灵活性**
    + `分区大小不等`
      + 划分为**多个**较小的分区、适量的中等分区、少量大分区

  + 为了**便于内存分配**，通常将分区按大小排队，并建立**分区说明表**，其中各表项包括**每个分区的始址、大小、状态（是否已分配）**

    + 当有用户程序要装入时，便**检索**该表，以找到合适的分区给予**分配**并将其状态置为**已分配**

    + 未找到**合适分区**时，则拒绝为该用户程序**分配**内存

      ![image-20220716180602894](../images/image-20220716180602894.png)

  + 这种方式存在两个问题

    + **程序可能太大**而放不进任何一个分区中，这时候用户不得不使用**覆盖技术**来使用内存空间
    + **主存利用率**低，当程序**小于**固定分区大小时，也占用一个**完整**的内存分区空间，这样分区内部就存在**空间浪费**，这种现象称为**内部碎片**

  + 固定分区是可用于**多道程序**设计的最简单的存储分配，无**外部碎片**，但不能实现**多进程共享一个主存区**，所以存储空间利用率**低**。很少用于**现代通用操作系统**，但可用于控制**多个相同对象**的控制系统

+ `动态分区分配` **可变分区分配**

  + 不预先划分内存，而是在进程装入内存时，根据进程的大小**动态**地建立分区，并使分区的大小正好适合进程的需要

    + 因此，系统中分区的**大小、数目**是可变的

      ![image-20220716182022217](../images/image-20220716182022217.png)

  + 动态分区在开始分配时是很好的，但之后会导致内存中出现许多**小**的内存块，即**外部碎片**，指在所有**分区外**的存储空间会变成越来越多的碎片，与固定分区的**内部碎片**正好相对。

    + 克服**外部碎片**可通过**紧凑技术（Compaction）**来解决，即操作系统不时地对**进程**进行移动、整理。但这需要**动态重定位寄存器**的支持，且相对费时
      + **紧凑**过程类似于Window系统中的**磁盘整理程序**，只不过后者是对**外存空间**的紧凑

  + 在**进程**装入或换入主存时，若内存中有**多个**足够大的空闲块，则操作系统必须确定分配哪个内存块给**进程**使用，这就是**动态分区**的分配策略

    + `首次适应（First Fit）`算法
      + 空闲分区以**地址递增**的次序链接。分配内存时**顺序查找**，找到大小能满足要求的**第一个**空闲分区
    + `最佳适应（Best Fit）`算法
      + 空闲分区按**容量递增**的方式形成**分区链**，找到第一个能满足要求的空闲分区
    + `最坏适应（Worst Fit）`算法 **最大适应（Largest Fit）**算法
      + 空闲分区以**容量递减**的次序链接，找到第一个能满足要求的空闲分区，即挑选出最大的分区。
    + `邻近适应（Next Fit）`算法 **循环首次适应**算法
      + 由**首次适应**算法演变而成。不同之处是，分配内存时，从**上次查找结束**的位置开始继续查找
    + 以上几种方法的评价
      + **首次适应算法**是**最简单、最好、最快的**。不过，**首次适应算法**会使得内存的**低地址部分**出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此增加了查找的**开销**
      + **邻近适应算法**试图解决这个问题，但实际上，它常导致在内存的**末尾**分配空间分裂成小碎片。（因为在一遍扫描中，内存**前面**部分**使用**后再**释放**，不会参与分配）。它通常比**首次适应算法**更差。
      + **最佳适应算法**虽然称为**最佳**，但是性能通常很差，因为每次最佳的分配会留下很小的**难以利用的内存块**，会产生**最多**的外部碎片
      + **最坏适应算法**与**最佳适应算法**相反，它把**最大**的连续内存划分开，会很快导致没有可用的**大内存块**，因此性能也非常差。

+ 三种**内存分区**管理方式的比较

  |                  |          作业道数          | 内部碎片 | 外部碎片 |                           硬件支持                           | 可用空间管理 | 解决碎片方法 | 解决空间不足 | 提高作业道数 |
  | ---------------- | :------------------------: | :------: | :------: | :----------------------------------------------------------: | :----------: | :----------: | :----------: | :----------: |
  | 单道连续分配     |             1              |    有    |    无    |                  界地址寄存器、越界检查机构                  |      -       |      -       |     覆盖     |     交换     |
  | 多道固定连续分配 | $\le N$（用户空间划为N块） |    有    |    无    | 上下界寄存器、越界检查机构、基地址寄存器、长度寄存器、动态地址转换机构 |      -       |      -       |      -       |      -       |
  | 多道可变连续分配 |             -              |    无    |    有    |                             同上                             |  数组、链表  |     紧凑     |      -       |      -       |

  以上三种内存分区管理方法有一个共同特点，即**用户进程（或作业）**在主存中都是**连续**存放的

### 非连续分配管理方式

+ 根据**分区大小是否固定**分为**分页存储管理方式**和**分段存储管理方式**

  + `分页存储管理方式`

    + 根据运行作业时是否要把作业的**所有页面**都装入内存才能运行，分为**基本分页存储管理方式**和**请求分页存储管理方式**

      + `基本分页存储管理方式`

        + **固定分区**产生**内部碎片**，**动态分区**产生**外部碎片**，这两种技术的内存利用率都比较低。这就引入了**分页**思想

          + 把**主存**空间划分为大小相等且固定的**块**，块相对较小，作为主存的**基本单位**。每个**进程**也以块为单位进行划分，进程在执行时，以**块**为单位逐个申请主存中的块空间

        + **分页**的方法从形式上看，像**分区相等**的**固定分区技术**，**分页管理不会产生外部碎片**。本质的不同点是**块的大小相对分区要小很多**，而且进程也按照块进行划分，进程运行时按**块**申请主存可用空间并执行。这样，**进程**只会在为最后一个不完整的块申请一个主存空间时，才产生**主存碎片**，所以尽管会产生**内部碎片**，但这种碎片相对于**进程**来说也是很小的，**每个进程平均只产生半个块大小的内部碎片**，也称**页内碎片**

        + 分页存储的几个**概念**

          + `页面和页面大小`

            + 进程中的**块**称为**页（Page）**，内存中的**块**称为**页框（Page Frame，或页帧）**。**外存**也以同样的单位进行划分，直接称为**块（Block）**。进程在执行时需要申请主存空间，即要为每个**页面**分配主存中的可用**页框**
            + 为方便**地址转换**，页面大小应该是**2的整数幂**。同时页面大小应该适中，页面太小会使进程的**页面数**过多，这样**页表**就会过长，占用大量内存，也会增加**硬件地址转换**的开销，降低页面**换入换出**的效率；页面过大又会使**页内碎片**增多，降低内存的利用率

          + `地址结构`

            + 逻辑地址结构如下

              ![image-20220718084638668](../images/image-20220718084638668.png)

            + 地址长度为**32**位，**0~11**位是页内地址，**12~31**位是页号，地址空间最多允许**$2^{20}$**页

            + 地址结构决定了**虚拟内存**的寻址空间有多大，在实际问题中，**页号、页内偏移、逻辑地址**大多都是用**十进制**数给出的。

              + 题目用**二进制**地址的形式给出时，读者要会转换

          + `页表`

            + 为了便于在内存中找到**进程**的每个页面所对应的物理块，系统为每个**进程**建立一张页表，它记录页面在内存中对应的**物理块号**，页表一般存放在内存中

            + 配置**页表**后，进程执行时，通过查找该表，即可找到每页在内存中的物理块号。

              > **页表**由**页表项**组成，**页表项**与**地址**都由两部分构成，第一部分都是**页号**，但**页表项**第二部分是物理内存中的块号，**地址**第二部分是页内偏移。**页表项**第二部分与**地址**第二部分共同组成物理地址。

              ![image-20220719083424728](../images/image-20220719083424728.png)

        + 基本地址变换机构

          + 将**逻辑地址**转换为内存中的**物理地址**，地址变换借助于**页表**实现

            ![image-20220719083600591](../images/image-20220719083600591.png)

          + 在系统中通常设置一个**页表寄存器（PTR）**，存放页表在内存的**起始地址F**和**页表长度M**。进程未执行时，页表的**始址、长度**存放在**进程控制块**中，当进程执行时，才将**页表始址、长度**存入**页表寄存器**。设**页面大小**为**L**，**逻辑地址A**到**物理地址E**的变换过程如下（逻辑地址、页号、每页的长度都是**十进制**数）

            + 计算**页号P**（P=A/L）和**页内偏移量W**（W=A%L）

            + 比较**页号P**和**页表长度M**，若**P >= M**，则产生越界中断，否则继续执行

            + 页表中**页号P**对应的**页表项地址** = **页表始址F + 页号P * 页表项长度**，取出该页表项**内容b**，即为**物理块号**。

              > 注意区分**页表长度**和**页表项长度**。**页表长度**的值是指一共有多少页，**页表项长度**是指页地址占多大的存储空间

            + 计算**E = b * L + W**，用得到的**物理地址E**去访问内存

          + 以上地址变换由**硬件**自动完成，**页式管理**只需给出一个整数就能确定对应的**物理地址**，因为**页面大小L**是固定的。因此，页式管理中地址空间是**一维**的

          + **页表项**的作用是找到该页在内存中的位置。以32位逻辑地址空间、字节编址单位、一页4KB为例，地址空间一共有**$2^{32}B/4KB=1M$**页，因此，需要**log1M=20**位才能保证表示范围能容纳所有页面，又因为**字节**作为编址单位，即页表项的大小**$>=\lceil 20/8 \rceil = 3B$**。所以在这个条件下，为了保证页表项能够指向所有页面，页表项的大小应该大于3B，当然，也可选择更大的页表项让一个页面能够正好容下整数个页表项，进而方便存储（如取成4B，一页正好可以装下1K个页表项），或增加一些其他信息

          + **分页管理方式**存在的两个主要**问题**

            + 每次访存操作都需要进行**逻辑地址**到**物理地址**的转换
              + **地址转换过程必须足够快**，否则访存速度会降低
            + 每个进程引入**页表**，用于存储映射机制
              + **页表不能太大**，否则内存利用率会降低

        + 具有**快表**的地址变换机构

          + 若**页表**全部放在内存中，则存取一个数据或一条指令至少要访问**两次内存**

            + **访问页表**，确定所存取的数据或指令的物理地址

            + 根据该地址**存取数据、指令**

              > 这种方法比**通常执行指令**的速度慢了一半

          + 为提高速度，在地址变换机构中增设一个具有**并行查找**能力的高速缓冲存储器--**快表**，又称**相联存储器（TLB）**，用来存放当前访问的若干**页表项**，以加速地址变换的过程。
          
            + 与此对应，主存中的页表常称为**慢表**
          
          + 具有**快表**的地址变换机构如下
          
            ![image-20220719102820142](../images/image-20220719102820142.png)
          
          + 具有**快表**的分页机制中，地址的变换过程如下
          
            + CPU给出**逻辑地址**后，由硬件进行**地址转换**，将页号送入**高速缓冲存储器**，并将此页号与**快表**中的所有页号进行比较
            + 若找到匹配的页号，说明所要访问的页表项就在**快表**中，则直接从中取出该页对应的**页框号**，与页内偏移量拼接形成**物理地址**。这样，存取数据仅一次访存便可实现
            + 若未找到匹配的页号，则需要访问**主存**中的页表，在读出页表项后，应同时将其**存入快表**，以便后面可能的再次访问。但若快表已满，则必须按照一定算法对旧的页表项进行替换。
          
          + 一般快表的命中率可达**90%**以上，这样分页带来的速度损失就可降低至**10%**以下。快表的有效性基于**局部性原理**
          
        + 两级页表
  
          + 使用**层次结构**的页表，将页表的10页空间也进行**地址映射**，建立上一级页表，用于存储页表的映射关系
  
            ![image-20220719103610248](../images/image-20220719103610248.png)
  
          + 二级页表实际上是在原有页表结构上再加上一层页表
  
            ![image-20220719103644752](../images/image-20220719103644752.png)
  
          + 建立多级页表的目的在于**建立索引**，以便不用浪费主存空间去存储无用的页表项，也不用盲目地顺序式查找页表项
  
      + `基本分段存储管理方式`
  
        + 与**分页**的区别联系
  
          + **分页**管理方式从**计算机**角度出发，目的是提高内存利用率，提升计算机的性能。通过**硬件机制**实现，对用户完全透明
          + **分段**管理方式从**用户、程序员**角度出发，满足方便编程、信息保护与共享、动态增长、动态链接等方面需求
  
        + `分段`
  
          + 按照用户进程中的**自然段**划分逻辑空间
  
            ![image-20220719104341698](../images/image-20220719104341698.png)
  
          + 页式系统中，逻辑地址的**页号、页内偏移量**对用户是透明的，但段式系统中，**段号、段内偏移量**必须由用户显式提供，在高级程序设计语言中，这个工作由**编译程序**完成
  
        + `段表`
  
          + 每个进程都有一张**逻辑空间**与**内存空间**映射的段表，其中每个段表项对应进程的一段，段表项记录该段在内存中的始址和长度
  
            ![image-20220719104727261](../images/image-20220719104727261.png)
  
          + 配置段表后，执行中的进程可通过查找段表，找到每段所对应的内存区
  
            + 即段表用于实现从**逻辑段**到**物理内存区**的映射
  
        + `地址变换机构`
  
          + 分段系统的地址变换如下图。为了实现进程从**逻辑地址**到**物理地址**的变换功能，在系统中设置了**段表寄存器**，用于存放**段表始址F**和**段表长度M**。从**逻辑地址A**到**物理地址E**之间的地址变换如下
  
            + 从**逻辑地址A**中取出前几位为**段号S**，后几位为**段内偏移量W**
              + 注意：**在段式存储管理的题目中，逻辑地址一般以二进制数给出，而在页式存储管理中，逻辑地址一般以十进制数给出**
            + 比较**段号S**和**段表长度M**，若**S >= M**，则产生越界中断，否则继续执行
            + 段表中**段号S**对应的**段表项地址 = 段表始址F + 段号S * 段表项长度**，取出该段表项的前几位得到**段长C**。若**段内偏移量 >= C**，则产生越界中断，否则继续执行。
              + **段表项**实际只有两部分，前几位是**段长**，后几位是**始址**
            + 取出**段表项**中该段的**始址b**，计算**E=b+W**，用得到的**物理地址E**去访问内存
  
            ![image-20220719105124746](../images/image-20220719105124746.png)
  
            ![image-20220719105142537](../images/image-20220719105142537.png)
  
        + `段的共享与保护`
  
          + 分段系统中，**段的共享**是通过两个作业的**段表**中相应表项指向被共享的段的同一个物理副本来实现的。当一个作业正从**共享段**中读取数据时，必须防止另一个作业修改此**共享段**中的数据。不能修改的代码称为**纯代码**或**可重入代码**（不属于临界资源），这样的**代码**和不能修改的**数据**可以共享，而可修改的**代码、数据**不能共享
  
        + 与**分页管理**类似，**分段管理**的保护方法主要有两种
  
          + **存取控制保护**
          + **地址越界保护**
            + 将**段表寄存器**中的**段表长度**与**逻辑地址**中的**段号**比较，若段号大于段表长度，则产生越界中断
            + 再将**段表项**中的**段长**与**逻辑地址**的**段内偏移**进行比较，若**段内偏移**大于**段长**，也会产生越界中断
  
        + **分页管理**中的地址越界保护只需要判断**页号**是否越界，页内偏移是不可能越界的
  
        + 与**页式管理**不同，段式管理不能通过给出一个**整数**便确定对应的物理地址，因为每段的长度是不固定的，无法通过整数除法得出**段号**，无法通过求余得出**段内偏移**，所以**段号**和**段内偏移**一定要显式给出，因此**分段管理的地址空间是二维的**
  
      + `段页式管理方式`
  
        + **页式存储管理**能有效的提高内存利用率，**分段存储管理方式**能反映程序的**逻辑结构**，有利于段的共享。
  
        + **段页式系统**中，作业的地址空间首先被分成若干**逻辑段**，每段都有自己的段号，然后将每段分成若干大小固定的**页**。对内存空间的管理仍然和**分页存储管理**一样，将其分成若干和**页面大小**相同的存储块，对内存的分配以**存储块**为单位。
  
        + 段页式系统中，作业的**逻辑地址**分三部分，**段号、页号、页内偏移量**，如下
  
          ![image-20220719111154053](../images/image-20220719111154053.png)
  
        + 为了实现**地址变换**，系统为每个进程建立一张**段表**，每个分段有一张**页表**。段表表项中至少包括**段号、页表长度、页表始址**，页表表项中至少包括**页号、块号**，此外，系统中还应有一个**段表寄存器**，指出作业的**段表始址、段表长度**
  
          > **段表寄存器**和**页表寄存器**的作用都有两个：一是**在段表、页表中寻址**，二是**判断是否越界**
  
        + 注意：**在一个进程中，段表只有一个，页表可能有多个**
  
        + **地址变换**时，通过**段表**查到**页表始址**，通过**页表**找到**页帧号**，最后形成**物理地址**。进行一次访问，实际需要**三次**访问主存，这里同样可以使用**快表**来加快查找速度，**关键字**由**段号、页号**组成，值是对应的**页帧号、保护码**
  
          ![image-20220719111708636](../images/image-20220719111708636.png)
  
        + **段页式管理的地址空间是二维的**

## 虚拟内存管理

### 虚拟内存的基本概念

+ 传统存储管理方式的特征
  + `一次性`
    + 作业必须**一次性全部**装入内存后，才能开始运行。这会导致两种情况
      + 当作业**很大**而不能全部被装入内存时，将使该作业无法运行
      + 当**大量**作业要求运行时，由于内存不足以容纳所有作业，只能使少数作业先运行，导致**多道程序度**的下降
  + `驻留性`
    + 作业被装入内存后，就一直驻留在内存中，其任何部分都不会被**换出**，直至作业运行结束。运行中的进程会因**等待IO**而被阻塞，可能处于长期等待状态
+ **局部性原理**
  + **高速缓存**是计算机科学中唯一重要的思想，依赖的原理就是**局部性原理**，表现在以下两个方面
    + `时间局部性`
      + 某条**指令、数据**一旦执行或访问，不久后可能再次执行或访问
        + 产生时间局部性的典型原因是程序中存在大量的**循环**
    + `空间局部性`
      + 一旦程序访问了某个存储单位，不久后，**附近的**存储单元也将被访问，即程序在一段时间内访问的地址，可能集中在一定的范围之内，因为指令通常是**顺序存放、顺序执行**的，数据也一般是以**向量、数组、表**等形式**簇聚存储**的
    + **时间局部性**通过将近来使用的**指令、数据**保存到**高速缓冲存储器**中。**空间局部性**通常使用较大的**高速缓存**，并将**预取机制**集成到**高速缓存控制逻辑**中实现。**虚拟内存**技术实际上建立了**内存-外存**的两级存储机构，利用**局部性原理**实现高速缓存。
+ **虚拟存储器**的定义和特征
  + 基于**局部性原理**，在程序装入时，将程序的一部分装入内存，而将其余部分留在**外存**，就可启动程序执行。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入**内存**，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容**换出**到外存上
  + 虚拟存储器有以下**三**个主要特征
    + `多次性`
      + 无须在作业运行时，一次性地全部装入内存，而允许被分成多次调入
    + `对换性`
      + 无须在作业运行时一直常驻内存，而允许在作业的运行过程中，进行**换出、换入**
    + `虚拟性`
      + 从**逻辑**上扩充内存容量，使用户所看到的内存容量远大于实际的内存容量
+ 虚拟内存技术的实现
    + 虚拟内存技术允许将一个作业分多次调入内存。采用**连续分配**时，会使相当一部分内存空间都处于**暂时**或**永久**的空闲状态，造成内存资源的严重浪费，而且也无法从**逻辑**上扩大内存容量。因此，虚拟内存的实现需要建立在离散分配的内存管理方式的基础上
    + 虚拟内存的实现有以下三种方式
        + `请求分页存储管理`
        + `请求分段存储管理`
        + `请求段页式存储管理`
    + 一般需要的硬件支持如下
        + 一定容量的**内存、外存**
        + **页表机制、段表机制**，作为主要的数据结构
        + **中断机构**，当用户程序要访问的部分尚未**调入**内存时，则产生中断
        + **地址变换机构**，逻辑地址到物理地址的变换

### 请求分页管理方式
+ 建立在基本分页系统基础之上，为了支持**虚拟存储器**而增加了**请求调页、页面置换**功能。是目前**最常用**的一种实现**虚拟存储器**的方法

+ `页表机制`

  + 不同于**基本分页系统**，请求分页系统在一个作业运行之前**不要求全部一次性**调入内存，因此在作业运行过程中，必然会出现**要访问的页面不在内存中**的情况，如何**发现、处理**这种情况？为此，在**请求页表项**中增加了**4**个字段，如下

    + `状态位P`
      + 指示该页是否**已调入内存**，供程序访问时参考

    + `访问字段A`
      + 用于记录本页在一段时间内**被访问过的次数**，或记录本页最近已有多长时间**未被访问**，供置换算法换出页面时参考

    + `修改位M`
      + 标识该页在调入内存后是否被修改过

    + `外存地址`
      + 用于指出该页在**外存**上的地址，通常是**物理块号**，供调入该页时参考

​									![image-20220719140947279](../images/image-20220719140947279.png)

+ `缺页中断机构`
    + 请求分页系统中，每当要访问的页面不在内存时，便产生一个**缺页中断**，请求操作系统将所缺的页面调入内存。此时应将缺页的进程**阻塞**（调页完成唤醒），若内存中有空闲块，则分配一个块，将要调入的页装入该块，并修改**页表**中的相应页表项，若此时内存中没有空闲块，则要淘汰某页（若被淘汰页在内存期间被修改过，则要将其写回外存）
    + **缺页中断**与**普通中断**的区别
      + 在执行指令期间，而非一条指令执行完后，产生和处理中断信号，属于**内部中断**
      + 一条指令在执行期间，可能产生多次缺页中断
    
+ `地址变换机构`
    + 是在**分页系统**地址变换机构的基础上，为实现虚拟内存，增加了某些功能形成的
        + 进行地址变换时，先检索**快表**

        + 若找到要访问的页，则修改**页表项**中的访问位（写指令还需要重置修改位），然后利用页表项中给出的**物理块号**和**页内地址**形成物理地址

        + 若未找到该页的**页表项**，则应到内存中去查找页表，再对比页表项中的**状态位P**，看该页是否已调入内存，未调入则产生**缺页中断**，请求从外存把该页调入内存

### 页面置换算法（决定应该换入哪页、换出哪页）

+ `最佳（OPT）置换算法`
  + 选择的被淘汰页面是**以后永不使用**的页面，或是在**最长时间内不再被访问**的页面，以便保证获得最低的缺页率。
    + 由于人们目前无法预知进程在内存下的若干页面中，哪个是未来最长时间内不再被访问的，因而该算法**无法实现**
    + **最长时间不被访问**和**以后被访问次数最小**是不同的概念

  + 可用来**评价**其他算法

+ `先进先出（FIFO）页面置换算法`
  + 优先淘汰**最早**进入内存的页面，即在内存中**驻留时间最久**的页面。该算法实现简单，只需要把调入内存的页面根据先后次序链接成队列，设置一个指针总指向最早的页面
    + 该算法与进程实际运行时的规律**不适应**，因为在进程中，有的页面经常被访问

  + FIFO算法还会产生所分配的**物理块数**增大而**页故障数**不减反增的异常现象，（由Belady发现），故称**Belady**异常。只有FIFO算法才会出现这种异常

+ `最近最久未使用（LRU）置换算法`
  + 选择**最近最长时间未访问过**的页面予以淘汰，它认为过去一段时间内未访问过的页面，在最近的将来可能也不会被访问。该算法为每个页面设置一个访问字段，来记录页面自上次被访问以来所经历的时间，淘汰页面时选择现有页面中**值最大**的予以淘汰。
  + LRU算法的性能较好，但需要**寄存器、栈**的硬件支持。LRU是堆栈类的算法，理论上可以证明，**堆栈类算法不可能出现Belady异常**，FIFO算法基于**队列**实现，不是堆栈类算法。


+ `时钟（CLOCK）置换算法`
  + **LRU**算法性能接近于**OPT**算法，但实现起来比较困难，且开销大；FIFO算法实现简单，但性能差。试图用比较小的开销接近LRU算法的性能，这类算法都是**CLOCK**算法的变体，因为算法要循环扫描缓冲区，像时钟的指针一样转动，所以称为**CLOCK**算法，又称**最近未使用（NRU，Not Recently Used）**算法
  + 简单的**CLOCK**算法給每帧关联一个**附加位**，称为**使用位**。当某页首次装入主存时，将该帧的**使用位**设置为**1**，当该页随后再被访问到时，其**使用位**也被置为**1**。对于页替换算法，用于替换的候选帧集合可视为一个**循环缓冲区**，并有一个指针与之相关联。当某一页被替换时，该指针被设置成指向缓冲区中的下一帧。当需要替换一页时，操作系统扫描缓冲区，以查找**使用位**被置为**0**的一帧。每当遇到一个**使用位**为**1**的帧时，操作系统将该位重新置**0**；若在这个过程开始时，缓冲区中的所有帧的**使用位**均为**0**，则选择遇到的第一个帧替换；若所有帧的**使用位**均为**1**，则指针在缓冲区中完整地循环一周，把所有**使用位**都置为**0**，并停留在最初的位置上，替换该帧中的页。由于该算法循环检查各页面的情况，因此称**CLOCK**算法
  + CLOCK算法的性能比较接近LRU算法，而通过增加使用的**位数目**，可以使得CLOCK算法更加高效。在**使用位**的基础上再增加一个**修改位**，则得到**改进型CLOCK置换算法**，这样，每帧都处于以下4种情况
    + 最近未被访问，也未被修改（**u=0，m=0**）
    + 最近被访问，但未被修改（**u=1，m=0**）
    + 最近未被访问，但被修改（**u=0，m=1**）
    + 最近被访问，被修改（**u=1，m=1**）

  + 算法执行如下操作步骤
    1. 从指针的当前位置开始，扫描帧缓冲区。在这次扫描过程中，对**使用位**不做任何修改。选择遇到的第一个帧（**u=0，m=0**）用于替换
    2. 若第一步**失败**，则重新扫描，查找（**u=0，m=1**）的帧。选择遇到的第一个这样的帧用于替换。在这个扫描过程中，对每个跳过的帧，把它的**使用位**设置成**0**
    3. 若第二步**失败**，则指针将回到它的最初位置，且集合中所有帧的使用位均为**0**。重复第**1**步，并且若有必要，重复第**2**步，以便可以找到供替换的帧

  +  **改进型**CLOCK算法优于简单CLOCK算法的地方在于**替换时，首选没有变化的页**，由于修改过的页在被替换之前必须写回，因而这样做会节省时间
  + **改进型**CLOCK算法与普通CLOCK算法区别
    + 操作系统中任何经过**优化**的页面置换算法都有一个原则
      + 尽可能保留曾经**使用过**的页面，而淘汰**未使用过**的页面，认为这样可以在总体上减少**换页次数**。

    + CLOCK算法只考虑到是否**被访问过**，因此被访问过的当然尽可能留下，未使用过的就淘汰；而**改进型**CLOCK算法对使用过的页面又做了细分，分为**使用过但未修改**和**使用过且修改过**，因此，若有未使用过的页面，则当然首先把它换出，若全部页面都使用过，则当然有限把**未修改过**的页面换出。


### 页面分配策略

+ 驻留集大小
  + 对于**分页式**的虚拟内存，在进程准备执行时，不需要、不可能把一个进程的所有页都读入主存。因此，操作系统决定读取多少页，即决定给特定的进程分配几个**页框**。给一个进程分配的**物理页框**的**集合**就是这个进程的驻留集。需要考虑以下几点
    + 分配给一个进程的**存储量**越小，任何时候驻留在主存中的进程数就越多，从而可以提高处理机的**时间利用效率**。
    + 若一个进程在竹村中的页数过少，则尽管有**局部性原理**，页错误率仍然会相对较高
    + 若页数过多，则由于**局部性原理**，给特定的进程分配更多的主存空间对该进程的错误率没有明显的影响
  + 现代操作系统通常采用**三**种策略
    + `固定分配局部置换`
      + 为每个进程分配**一定数目**的物理块，在整个运行期间都**不改变**。若进程在运行中发生**缺页**，则只能从**该进程在内存中的页面**中选出一页换出，然后调入需要的页面。
      + 这种策略，**难以确定**应为每个进程分配的**物理块数目**
        + **太少**，会频繁出现缺页中断
        + **太多**，会使CPU和其他资源利用率下降
    + `可变分配全局置换`
      + **最容易**实现的策略
      + 为系统中的每个进程分配一定数目的物理块，操作系统自身也**保持一个空闲物理块队列**，当某进程发生缺页时，系统从空闲物理块队列中取出一个物理块分配给该进程，并将欲调入的页装入其中。这种方法比固定分配局部置换更加灵活，可以动态增加进程的物理块，但也存在**弊端**
        + 会盲目地给进程增加物理块，从而导致系统多道程序的**并发能力**下降
    + `可变分配局部置换`
      + 为每个进程分配一定数目的物理块，当某个进程发生缺页时，只允许从**该进程在内存的页面**中选出一页换出，因此不会影响其他进程的运行。
      + 若进程在运行中频繁地缺页，则系统再为该进程分配若干物理块，直至该进程**缺页率**趋于适当程度；反之，若进程运行中的**缺页率**特别低，则可适当减少分配给该进程的物理块
        + 比起可变分配全局置换，这种方法不仅可以动态地增加进程物理块地数量，还能动态减少进程物理块地数量，在保证进程不会过多地调页地同时，也保持了系统的多道程序并发能力。
+ 调入页面的时机
  + `预调页策略`
    + 根据**局部性原理**，一次调入若干相邻的页可能会比一次调入一页更高效。但若调入的一批页面中大多数都未被访问，则又是低效的。因此需要采用**预测**为基础的预调页策略，将预计在不久之后便会被访问的页面预先调入内存。
      + 目前预调页的成功率在50%左右，因此该策略主要用于进程的**首次调入**，由程序员指定应先调入哪些页
  + `请求调页策略`
    + 进程在运行中需要访问的页面不在内存而提出请求，由系统将所需页面调入内存。由这种策略调入的页一定会被访问，且这种策略比较易于实现，因此在目前的虚拟存储器中多大采用此策略。
      + **缺点**时每次只调入一页，调入调出页面数多时会**花费过多的IO开销**
  + **预调入**实际上就是运行前调入，**请求调页**实际上就是运行期间调入。一般情况下，两种策略都会用到
+ 从何处调入页面
  + 请求分页系统中的**外存**分两部分
    + 用于存放文件的**文件区**
      + 采用**离散分配**方式
    + 用于存放对换页面的**对换区**
      + 对换区通常采用**连续分配**方式，因此对换区的磁盘IO速度比**文件区**的更快
  + 从何处调入页面存在**三**种情况
    + `系统拥有足够的对换空间`
      + 可以全部从**对换区**调入所需页面，以提高调页速度
        + 在进程运行前，需将与该进程有关的文件从**文件区**复制到**对换区**
    + `系统缺少足够的对换区空间`
      + 不会被修改的文件都直接从**文件区**调入。换出这些页面时，由于它们未被修改而不必将它们换出。但对于可能被修改的部分，在将它们换出时必须调到**对换区**，以后需要时再从**对换区**调入
        + 因为**读**的速度比**写**快
    + `UNIX方式`
      + 与**进程**有关的文件都放在**文件区**，因此未运行过的页面都应从**文件区**调入。曾经运行过但又被换出的页面，由于放在**对换区**，因此下次调入时应从**对换区**调入。进程请求的共享页面若被其他进程调入内存，则无须再从**对换区**调入。

### 抖动

+ 页面置换过程中，刚刚**换出**的页面马上又要**换入**主存，刚刚**换入**的页面马上又要**换出**主存，这种频繁的页面调度行为称为**抖动、颠簸**
  + 若一个进程在**换页**上用的时间多于**执行**时间，则这个进程就在**颠簸**
+ 频繁发生**缺页中断（抖动）**的主要原因
  + 某个进程频繁访问的页面数目**高于**可用的物理页帧数目
+ **虚拟内存**技术可在内存中保留更多的进程以提高系统效率。在**稳定**状态，几乎主存的所有空间都被**进程块**占据，处理机和操作系统可以直接访问到尽可能多的进程。
  + 如果管理不当，那么处理机的大部分时间都将用于**交换块**，即请求调入页面的操作，而不是执行进程的指令，因为会大大降低系统效率。

### 工作集

+ 在某段时间间隔内，进程要访问的页面集合。基于**局部性原理**，可以用最近访问过的页面来确定工作集。
  + 一般来说，工作集**W**可由时间**t**和工作集窗口大小**$\Delta$**来确定
+ 实际应用中，**工作集窗口**会设置的很大，即对于**局部性**好的程序，工作集大小一般会比工作集窗口**$\Delta$**小很多。
+ 工作集反映了进程在接下来的**一段时间内**很有可能会频繁访问的页面集合，因此，若分配给进程的**物理块**小于工作集大小，则该进程就很有可能频繁**缺页**，所以为了防止这种**抖动现象**，一般来说分配进程的**物理块数**（即**驻留集**大小）要**大于**工作集大小
+ 工作集模型的**原理**
  + 让操作系统跟踪每个**进程**的工作集，并为进程分配大于其工作集的**物理块**
  + 落在**工作集**内的页面需要调入**驻留集**中，而落在**工作集**外的页面可以从**驻留集**中换出
  + 若还有**空闲物理块**，则可以再调一个进程到内存以增加**多道程序数**
  + 若所有进程的**工作集之和**超过了**可用物理块**的总数，则操作系统会暂停一个进程，将其页面调出并将物理块分配给其他进程，防止出现**抖动**现象

### 地址翻译



# 文件管理

## 文件系统基础
## 文件系统实现
## 磁盘组织与管理

# 输入/输出管理
## I/O管理概述
## I/O核心子系统
